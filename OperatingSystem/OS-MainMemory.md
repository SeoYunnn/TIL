# Chapter 09 메인 메모리

## 💭 배경

📢 ***메인 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할***

<br>
메모리는 각각 주소가 할당된 일련의 바이트들로 구성

CPU는 PC가 지시하는 대로 메모리부터 다음 수행할 명령어를 가져오는데, 그 명령어는 필요한 경우 추가적인 데이터를 더 가져올 수 있으며, 반대로 데이터를 메모리로 내보낼 수도 있음

<br>
<br>

### 1. 기본 하드웨어

메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치

기계 명령어들은 메모리 주소만을 인수로 취하고, 디스크의 주소를 인수로 취하지 않음

👉🏻 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 **메인 메모리**와 **레지스터**에 있어야 함

if) 데이터가 메모리에 없다면 ? ⇒ **CPU가 처리하기 전 메모리로 이동**시켜야 함

<br>

각 CPU 코어에 내장된 레지스터들은 일반적으로 **CPU 클록의 1사이클 내에 접근 가능**

일부 처리 코어들은 레지스터에 있는 명령어의 해독과 간단한 연산을 클록 틱(clock tick)당 하나 또는 그 이상의 속도로 처리함

- clock tick : CPU의 클럭 신호가 한 번 발생하는 시간 간격을 의미, 이 시간 간격동안 CPU는 작업을 수행

<br>

**But,** 메모리 버스를 통해 전송되는 메인 메모리의 경우는 앞에서 언급했던 상황과는 다름

메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요되며, 이 경우 **CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연**되는 **stall 현상**이 발생하게 됨

<br>

**🙌🏻 해결방법**

**✅** CPU와 메인 메모리 사이에 빠른 속도의 메모리를 추가

**✅** CPU에 구축된 캐시를 관리해 하드웨어는 어떠한 운영체제의 도움 없이 메모리 접근 속도를 향상

<br>
<br>

물리 메모리의 상대적인 접근 속도의 차이를 고려하는 것에 추가로 올바른 동작을 보장해야만 함

시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐 아니라, 사용자 프로그램 사이도 서로 보호해야 함

**운영체제가 CPU와 메모리 간 접근 중에 개입하게 되면 성능이 떨어지기 때문에** 이러한 보호 기법은 반드시 **하드웨어가 지원**해야 함

![image](https://github.com/SeoYunnn/TIL/assets/120713987/65067188-f4b9-426f-8ef0-a5b9b4e4a2a3)

<br>

먼저 각각 프로세스가 독립된 메모리 공간을 가지도록 보장해야 함

개별적인 프로세스 별 메모리 공간은 서로를 보호하고, 병행 실행을 위해 여러 프로세스가 메모리에 적재되게 하는 것이 필수적임

개별적 메모리 공간을 분리하기 위해 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 설정하고, 프로세스가 합법적인 영역만을 접근하도록 하는 것이 필요

그림처럼, **기준(base)** 과 **상한(limit)** 이라고 불리는 두 개의 레지스터를 활용해 보호 기법을 제공

- 기준 레지스터 : 가장 작은 합법적인 물리 메모리 주소의 값을 저장
- 상한 레지스터 : 주어진 영역의 크기를 저장

ex) 기준 레지스터 값이 `300040` 이고, 상한 레지스터의 값이 `120900` 이라면 프로그램은 `300040`~`420940` 까지 모든 주소를 접근 가능

![image](https://github.com/SeoYunnn/TIL/assets/120713987/ab070a86-3d8b-4d9b-81af-5aa54447d662)

<br>

메모리 공간의 보호는 CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어짐

사용자 모드에서 수행되는 프로그램이 운영체제의 메모리 공간이나 다른 사용자 프로그램의 메모리 공간에 접근하면 운영체제는 치명적인 오류로 간주하고, **trap**을 발생시킴

사용자 프로그램이 우연히든, 의도적이든 간에 운영체제나 **다른 사용자 프로그램의 코드나 데이터 구조를 수정하는 것을 막음**

<br>

기준과 상한 레지스터는 여러 가지 **특권 명령(special privileged instruction)** 을 사용하는 운영체제에 의해서만 **적재(load)** 됨

오직 커널 모드에서 수행되기 때문에 **운영체제만 레지스터들의 값을 변경할 수 있도록 허가**해 줌으로써 **사용자 프로그램이 레지스터의 내용을 변경하는 것을 막음**

<br>

커널 모드에서 수행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지 않음

운영체제는 사용자 프로그램을 사용자 메모리 영역의 적재, 오류가 발생한 경우에 그 프로그램을 덤프(dump out), 시스템 콜의 매개변수를 변경, 사용자 메모리로부터의 입출력과 다른 많은 서비스를 제공할 수 있음

ex) 다중 처리기 시스템 운영체제는 한 프로세스의 상태를 레지스터로부터 메인 메모리로 저장하고, 다음 프로세스의 문맥을 메인 메모리로부터 레지스토로 저장하는 문맥 교환을 반드시 실행해야 함

<br>
<br>

### 2. 주소의 할당

프로그램은 원래 이진 실행 파일 형태로 디스크에 저장되어 있기 때문에 실행하기 위해선 프로그램을 메모리로 가져와서 프로세스 문맥 내에 배치해야 함

이 시점에 가용한 CPU에서 실행할 수 있게 되는데, 프로세스가 실행되면 메모리에서 명령 및 데이터에 엑세스 함

결국 프로세스가 종료되고 다른 프로세스에서 사용하기 위해 메모리가 회수됨

<br>

대부분 시스템은 사용자 프로세스가 메모리 내 어느 부분으로도 올라올 수 있도록 지원하고 있음

사용자 프로세스의 주소가 `00000` 번지부터 시작된다고 해서 굳이 `00000` 번지부터 올라와야 할 필요는 없음

대부분의 경우 사용자 프로그램은 다음과 같이 여러 단계를 거쳐 실행되기 때문에 이들 단계를 거치는 동안 주소들은 여러 가지 다른 표현 방식을 거치게 됨

![image](https://github.com/SeoYunnn/TIL/assets/120713987/39395045-6f59-4716-8aff-be8398923d88)

**1️⃣ 컴파일 시간(compile time) 바인딩**

- 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대 코드**를 생성할 수 있음
    - 절대 코드 : 프로그램이 메모리에 로드될 때 주소가 정적으로 할당되어 있는 코드를 의미

ex) 사용자 프로세스가 `R` 번지로부터 시작한다는 것을 미리 알 수 있다면 컴파일러는 번역할 코드를 그 위치에서 시작해 나가지만 위치가 변경되어야 한다면 다시 컴파일 되어야 함

<br>
<br>

**2️⃣ 적재 시간(load time) 바인딩**

- 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면, 컴파일러는 일단 이진 코드를 **재배치 가능 코드**로 만들어야 함
- 이 경우 심볼과 진짜 번지수와의 바인딩은 프로그램이 메인 메모리로 실제로 적재되는 시간에 이루어지게 됨
- 재배치 가능 코드는 시작 주소가 변경되면, 아무 때나 사용자 코드를 다시 적재하기만 하면 됨

<br>
<br>

**3️⃣ 실행 시간(execution time) 바인딩**

- 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있다면, 바인딩이 실행 시간까지 허용되었다고 이야기 함
- 이런 것이 가능해지려면 특별한 하드웨어를 이용해야 함

<br>
<br>

### 3. 논리 대 물리 주소 공간

CPU가 생성하는 주소를 일반적으로 **논리 주소(logical address)** 라 하며, 반면에 메모리가 취급하게 되는 주소 즉, **메모리 주소 레지스터(MAR)** 에 주어지는 주소는 일반적으로 **물리 주소(physical address)** 라 함

<br>

컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같음

**But,** 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다름 👉🏻 논리 주소를 **가상 주소(virtual address)** 라 함 

프로그램에 의해 생성된 모든 논리 주소 집합을 **논리 주소 공간(logical address space)** 이라 하며, 이 논리 주소와 일치하는 모든 물리 주소 집합을 **물리 주소 공간(physical address space)** 이라 함

![image](https://github.com/SeoYunnn/TIL/assets/120713987/91b0bda9-f495-4a65-a7e8-ef6dbe21e6ba)

<br>

프로그램의 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꿔줘야 하는데, 이 변환(mapping) 작업은 하드웨어 장치인 **메모리 관리 장치(MMU)**에 의해 실행됨

변환을 수행하기 위해 여러 가지 방법 중에서 선택할 수 있는데, 우선 여기에서는 기준 레지스터(base register) 기법을 일반화시킨 아주 단순한 MMU기법에 따른 변환을 설명

![image](https://github.com/SeoYunnn/TIL/assets/120713987/2c015c51-8bb5-44d9-ac53-c6bc97ff918f)

기준 레지스터를 **재배치(relocation) 레지스터**라 부름

재배치 레지스터 속에 들어있는 값은 주소가 메모리로 보내질 때마다 그 모든 주소에 더해짐

<br>

**사용자 프로그램은 절대로 실제적 물리 주소에 접근하지 않음**

사용자 프로그램은 `364` 번지에 대한 포인터를 생성해서 그것에 대해 저장, 연산, 다른 주소들과 비교하는 등 온갖 일을 할 수 있지만 그것이 주소(간접 적재 및 저장)로 갈 때는 기준 레지스터에 대해 다시 바인딩 됨

사용자 프로그램은 논리 주소를 사용한 것이고, 메모리 하드웨어는 논리 주소를 실제 주소로 바꾼 것

참조된 메모리 주소의 실제 위치는 이 참조가 실제 실행 시간에 결정됨

<br>

이제는 두 가지 주소, 즉 논리 주소(`0` ~ `max` 까지 범위)와 실제 주소(기준값 R에 대해 `R+0` 에서 `R+max` 까지 범위)가 있다는 사실에 주의해야 함

<br>
<br>

### 4. 동적 적재

📢 ***메모리 공간의 더 효율적 이용을 위해서는 동적 적재(dynamic loading)를 해야 함***

<br>

**동적 적재**에서 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않고, 재배치 가능한 상태로 디스크에서 대기하고 있음

먼저 `main` 프로그램이 메모리에 올라와 실행됨

이 루틴이 다른 루틴을 호출하게 되면 호출된 루틴이 이미 메모리에 적재됐는지를 조사함

if) 적재되어 있지 않다면 ? ⇒ **재배치 가능 연결 적재기(relocatable linking loader)** 가 불려 요구된 루틴을 메모리로 가져오고, 테이블에 기록

<br>
<br>

> ***동적 적재**는 루틴이 필요한 경우에만 적재된다는 점에서 이점을 지니며, 오류 처리 루틴처럼 아주 간혹 발생하면서도 실행할 코드가 많은 경우에 특히 유용함*
>

<br>
<br>

### 5. 동적 연결 및 공유 라이브러리

📢 ***동적 연결 및 공유 라이브러리(DLL) : 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리***

<br>

어떤 운영체제는 **정적 연결(static linking)** 만을 지원하는데, 이 경우에는 라이브러리가 이 프로그램의 이진 프로그램 이미지에 끼어 들어가게 됨

**But,** **동적 연결 개념은 동적 적재의 개념과 유사**함

<br>

**동적 적재에서는 로딩(loading)이 실행 시까지 미루어졌었지만, 동적 연결에서는 연결(linking)이 실행 시기까지 미루어지는 것**

동적 연결은 주로 표준 `C` 언어 라이브러리와 같은 시스템 라이브러리에 사용됨

이 기능이 없으면 시스템의 각 프로그램은 실행 가능 이미지에 해당 언어 라이브러리의 사본을 포함해야 함

👉🏻 이 요구 사항은 **실행 가능 이미지의 크기를 증가**시킬 뿐 아니라 **메인 메모리를 낭비**할 수도 있음

<br>

또한, DLL은 라이브러리를 여러 프로세스 간에 공유할 수 있어, 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있음

👉🏻 공유 라이브러리라고도 하며, `Windows` 및 `Linux` 시스템에서 광범위하게 사용

<br>

프로그램이 동적 라이브러리에 있는 루틴을 참조하면 로더는 DLL을 찾아 필요한 경우 메모리에 적재

그 후 다음 동적 라이브러리의 함수를 참조하는 주소를 DLL이 저장된 메모리의 위치로 조정

<br>
<br>

동적 연결 라이브러리는 라이브러리 갱신으로(버그 수정 등) 확장할 수 있으며, 언제나 새로운 버전으로 교체될 수 있음 👉🏻 해당 라이브러리를 사용하는 모든 프로그램은 자동으로 새로운 라이브러리 버전을 사용하게 될 것

if) 동적 연결이 없었다면 ? ⇒ 새로운 라이브러리를 사용하기 위해 **모든 프로그램은 새로 링크** 되어야 함

<br>
<br>

> *동적 적재와는 달리 **동적 연결과 공유 라이브러리는 일반적으로 운영체제의 도움이 필요**
메모리에 있는 프로세스들의 각자 공간이 자신만 액세스 할 수 있도록 보호 된다면 **운영체제만이 기억 공간에 루틴이 있는지를 검사할 수 있고, 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록** 해줄 수 있음*
>

<br>
<br>

## 💭 연속 메모리 할당

메모리는 일반적으로 두 개의 부분으로 나뉨

*1) 운영체제를 위해*

*2) 사용자 프로세스를 위해*

<br>

일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하기를 원함 👉🏻 메모리에 적재되기를 기다리는 프로세스에 사용 가능한 메모리를 할당하는 방법을 고려

연속적 메모리 할당에서 각 프로세스는 다음 프로세스가 적재된 영역과 인접한 하나의 메모리 영역에 적재됨

**But,** 앞서 **메모리 보호 문제를 해결**해야 함

<br>
<br>

### 1. 메모리 보호

![image](https://github.com/SeoYunnn/TIL/assets/120713987/baa8f991-8ae6-4fc4-9d15-9e37f99bf71d)

<br>

재배치 레지스터는 가장 작은 물리 주소의 값을 저장하고, 상한 레지스터는 논리 주소의 범위 값을 저장

각각의 논리 주소는 상한 레지스터가 지정한 범위 안에 존재해야 함

MMU는 동적으로 논리 주소에 재배치 레지스터의 값을 더함으로써 주소를 변환하는 역할을 하는데, 변환된 주소는 메모리로 보내짐

<br>

CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때, **디스패처(dispatcher)** 는 **재배치 레지스터와 상한 레지스터에 정확한 값을 적재**함

CPU에 의해서 생성되는 모든 주소는 레지스터들의 값을 참조해서 확인 작업을 거치기 때문에, 운영체제와 다른 사용자 프로그램을 현재 수행 중인 사용자 프로그램의 접근으로부터 보호 가능

<br>
<br>

> *재배치 레지스터를 사용함으로써 운영체제의 크기는 실행 중이라도 얼마든지 변경될 수 있으며 매우 유용하게 쓰일 수 있음
ex) 장치 드라이버가 더 필요하지 않은 경우 장치 드라이버를 제거하고 메모리를 다른 요청에 할당할 수 있음*
>

<br>
<br>

### 2. 메모리 할당

메모리 할당하는 가장 간단한 방법 중 하나는 프로세스를 메모리 가변 크기 파티션에 할당하는 것

각 파티션에는 정확히 하나의 프로세스만 적재 가능

<br>

**가변 파티션 기법**에서 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지함

처음에는 모든 메모리가 사용자 프로세스에 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록인 **hole** 로 간주

- hole : 할당되지 않은 메모리 영역을 말함 👉🏻 사용 가능한 메모리 블록 중에서 **프로세스에 할당되지 않은 부분**

![image](https://github.com/SeoYunnn/TIL/assets/120713987/0a4264dd-32ba-4bf9-a769-7731200d6afa)

<br>

**◎ 9.7 설명**

처음에는 프로세스 `5`, `8`, `2` 가 적재되어 있고 메모리가 완전히 활용 상태

프로세스 `8` 이 종료된 후 하나의 연속된 hole 이 생김

나중에 프로세스 `9` 가 도착하고 메모리가 할당

프로세스 `5` 가 종료되면 두 개의 연속되지 않은 hole 생성

<br>
<br>

프로세스가 시스템에 들어오면 운영체제는 각 프로세스가 메모리를 얼마나 요구하며, 또 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려해 공간을 할당함

프로세스가 공간을 할당받게 되면, 이후로는 CPU를 할당받기 위해 경쟁

<br>

**🤔 도착 프로세스의 요구를 충족시키기에 메모리가 충분하지 않으면 어떻게 되는가 ?**

*1) 단순히 프로세스를 거부하고 적절한 오류 메세지를 제공*

*2) 메모리가 나중에 해제되면 운영체제는 대기 큐를 검사해 대기 프로세스의 메모리 요구를 충족시킬지 여부를 결정*

<br>
<br>

일반적으로 메모리에는 다양한 크기의 hole 이 여기저기 산재하게 되는데 **프로세스에 공간이 필요할 때 운영체제는hole의 집합에서 적절한 것을 찾아내야 함**

찾은 hole이 요청한 것보다 약간 크면 두 개로 나누어 한 조각은 프로세스에 할당하고, 나머지 하나는 hole 집합으로 되돌아감

그 프로세스가 끝나면 공간은 hole의 집합으로 되돌아가고, 새로운 hole이 다른 hole과 인접해 있다면, 이 두 개의 블록을 합쳐서 한 개의 큰 hole로 만들음

<br>

이러한 기법은 **“동적 메모리 할당 문제”** 의 특별한 예시 중 하나

일련의 가용 공간-리스트로부터 크기 n-바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제

즉, **메모리 할당 알고리즘이 어떻게 효율적으로 메모리를 할당할지 결정하는 문제**

<br>

**🙌🏻 해결방법**

- **최초 적합(first fit)**
    - 첫 번째 사용 가능한 가용 공간 할당
    - 검색은 집합의 시작에서부터 하거나 검색이 끝났던 곳에서 시작될 수 있음
    - 충분히 큰 가용 공간을 찾았을 경우 검색을 끝낼 수 있음
- **최적 적합(best fit)**
    - 사용 가능한 공간 중 가장 작은 것을 택함
    - 리스트가 크기 순으로 되어 있지 않다면 전 리스트를 검색해야만 함
    - 아주 작은 가용 공간을 만들어냄
- **최악 적합(worst fit)**
    - 가장 큰 가용 공간을 택함
    - 할당해 주고 남는 가용 공간은 충분히 크기에 다른 프로세스들을 위해 유용하게 사용 가능
    - 이때, 가용 공간들이 크기 순으로 정렬되어 있지 않으면 전 리스트를 다 검색해야 함

<br>
<br>

> *모의실험을 통해 연구했을 때, **최초 적합과 최적 적합 모두 시간과 메모리 이용 효율 측면에서 최악 적합보다 좋다**는 것이 입증되었음
공간 효율성 측면에서는 어느 것이 항상 더 좋다고 말할 수는 없지만 **최초 적합이 일반적으로 속도가 더 빠름***
>

<br>
<br>

### 3. 단편화

**♦︎ 외부 단편화**

최초 적합, 최적 적합 전략 모두 **외부 단편화(external fragmentation)** 로 인해 문제를 겪음

프로세스들이 메모리에 적재되고 제거되는 일이 반복되면 어떤 가용 공간은 너무 작은 조각이 됨

외부 단편화는 **유휴 공간들을 모두 합치면 충분한 공간이 되지만 너무 작은 조각들로 여러 곳에 분산되어 있을 경우 발생**

👉🏻 메모리는 너무 많은 수의 매우 작은 조각들로 단편화되어 있음

👉🏻 최악의 경우로는 **모든 프로세스 사이마다 못 쓰게 된 가용 공간을 가질 수 있음**

<br>

메모리의 전체 크기와 프로세스 크기들은 모두 외부 단편화에 따라 큰 영향을 미칠 수 있음

ex) 최초 적합의 경우 `N` 개 블록이 할당되었을 때 `0.5N` 개 블록이 단편화 때문에 손실될 수 있다는 것을 알 수 있음

*👉🏻* ***50% 규칙**(절반 이상이 외부 단편화로 인해 손실)*

<br>
<br>

**♦︎ 내부 단편화**

내부적으로도 단편화가 발생할 수 있는데, 그에 대한 예시를 살펴보자

`18,464B` 크기의 가용 공간을 생각했을 때, 어느 한 프로세스가 `18,462B` 를 요구한다고 가정해보자

요구된 블록을 정확히 할당하면 `2B` 의 가용 공간이 남게 되는데, 가용 공간을 놓치지 않기 위해 오히려 더 큰 부담을 시스템이 가지게 될 수 있음

일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고, 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수배로만 해주는 것이 보통의 경우

**But,** 예시된 경우에서는 할당된 공간이 요구된 공간보다 약간 더 클 수 있음

👉🏻 두 크기 사이의 남는 부분이 ***“내부 단편화(internal fragmentation)”***

<br>
<br>

**🙌🏻 해결방법**

✅ **압축(compaction)**

👉🏻 메모리 모든 내용을 한 군데로 몰고 모든 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만드는 방법

<br>

**But,** 항상 압축이 가능한 것은 아님

재배치가 어셈블 또는 적재 시에 정적으로 행해진다면, 압축은 실행될 수 없음

압축은 프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만 가능

주소가 동적으로 재배치할 수 있다면, 재배치 작업은 프로그램과 데이터를 새로운 위치로 옮기고 새 위치를 반영하기 위해 기준 레지스터만 변경하면 완료됨

압축이 가능하더라도 그 비용을 검토해봐야 함

<br>

가장 간단한 압축 알고리즘은 단순히 모든 프로세스를 한쪽 끝으로 이동시켜 모든 가용 공간이 그 반대 방향으로 모이도록 하는 방법이지만 비용이 너무 많이 들음

<br>

**✅ 페이징(paging)**

<br>
<br>

## 💭 페이징

지금까지 논의된 메모리 관리는 프로세스의 물리 주소 공간이 연속적이어야 했음

이제 프로세스의 물리 주소 공간이 연속되지 않아도 되는 메모리 관리 기법인 **페이징**을 알아보자

<br>
<br>

### 1. 기본 방법

물리 메모리는 **프레임(frame)** 이라 불리는 같은 크기 블록으로 나누어짐

논리 메모리는 **페이지(page)** 라 불리는 같은 크기의 블록으로 나누어짐

프로세스가 실행될 때 그 프로세스의 페이지는 파일 시스템 또는 예비 저장장치로부터 가용한 메인 메모리 프레임으로 적재됨

예비 저장장치는 메모리 프레임 혹은 프레임의 묶음인 클러스터와 동일한 크기의 고정 크기 블록으로 나뉨

<img width="581" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/aa0e0a13-31b2-4ac4-9e51-4c54202d2349">

CPU에서 나오는 모든 주소는 **페이지 번호(p)** 와 **페이지 오프셋(d: offset)** 두 개의 부분으로 나뉨

<img width="808" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6a0d4321-0e2d-42cb-aa43-083b9cf15756">

페이지 번호는 프로세스 **페이지 테이블(page table)**을 액세스 할 때 사용됨

페이지 테이블은 물리 메모리의 각 프레임의 시작 주소를 저장하고 있으며, 오프셋은 참조되는 프레임 안에서의 위치

프레임의 시작 주소와 페이지 오프셋이 결합해 물리 메모리 주소가 됨

<br>

<img width="805" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3e5ac1a2-f25b-4fec-af0d-03420973b6fe">

<br>

ex) 논리 주소 `13` → 실제 주소 `9`

<img width="790" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3b36505a-a7f4-4a0e-afe1-76ce385579b9">

<img width="802" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/582cfedb-4bda-476b-ad0d-1609b82e4511">

모든 놀고 있는 프레임이 프로세스에 할당될 수 있기 때문에 페이징 기법을 사용하면 외부 단편화가 발생하지 않음

할당은 항상 프레임의 정수배로 할당되기 때문에 이제는 **내부 단편화가 발생**

페이징 자체는 동적 재배치의 형태이기 때문에 모든 논리 주소는 페이징 하드웨어에 의해 물리 주소로 사상됨

<br>

<img width="843" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/9b889af1-490a-43cb-af5e-5723c8a950bc">

한 프로세스가 실행되기 위해 도착하면 그 프로세스의 크기가 페이지 몇 개 분에 해당하는가를 조사함

각 사용자 페이지는 한 프레임씩이 필요 👉🏻 프로세스가 `n`개 페이지를 요구하면 메모리에서 이용할 수 있는 프레임이 `n`개 있어야 함

`n` 개의 프레임을 사용할 수 있다면 이 프레임들은 이 프로세스에 할당함

그리고는 프로세스의 처음 페이지가 할당된 프레임 중 하나에 적재되고, 그 프레임 번호가 페이지 테이블에 기록됨

그 다음 페이지는 또 다른 프레임에 적재되고, 또 그 프레임 번호가 페이지 테이블에 기록되며 과정이 반복됨

<br>

**❗️메모리에 대한 사용자 인식과 실제 내용이 서로 다름**

프로그래머는 메모리가 하나의 연속적인 공간이며, 메모리에는 이 프로그램만 있다고 생각하지만, 실제로 프로그램은 여러 곳에 프레임 단위로 분산되어 있고 많은 프로그램이 올라와 있음

프로그래머가 생각하는 메모리와 실제 물리 메모리 차이는 주소 변환 하드웨어에 의해 해소됨

논리 주소는 물리 주소로 변환되며, 이 사상은 운영체제에 의해 조정됨

운영체제는 모든 프로세스의 주소들을 실제 주소로 사상할 수 있어야 함

만약 사용자가 시스템 콜을 호출해 인자로 어떤 주소를 주면, 제대로 사상해 정확히 그 물리 주소를 찾아가야 함

<br>
<br>

운영체제는 명령 카운터와 레지스터의 사본을 유지하는 것처럼 각 프로세스의 페이지 테이블 사본을 유지함

이 사본은 운영체제가 논리 주소에 대응하는 물리 주소를 직접 사상해야 할 때마다 논리 주소를 물리 주소로 변환하는 데 사용됨

또한 프로세스가 CPU에 할당될 때 CPU 디스패처가 하드웨어 디스패처 테이블을 설정하는 데 사용됨

***👉🏻 페이징은 문맥 교환 시간을 늘림***

<br>
<br>

### 2. 하드웨어 지원

대부분의 컴퓨터는 **페이지 테이블을 메모리에 저장**함

페이지 테이블 기준 레지스터(PTBR)가 페이지 테이블을 가리키고, 페이지 테이블 길이 레지스터(PTLR)가 페이지 테이블의 크기 값을 가짐

**But,** 문맥 교환 속도가 빨라지지만 **메모리 위치에 접근하는데 많은 시간이 소요**됨

모든 데이터/명령에 대한 접근에 두 번의 메모리 접근이 필요함

- 페이지 테이블을 위해 한 번 + 데이터/명령 을 위해 한 번

<br>
<br>

**🙌🏻 해결방법**

**✅ TLB(Translation Look-aside Buffers)**

<img width="352" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/ad9e619d-cb1f-4f7b-9a5b-904e17eec822">

매우 빠른 연관 메모리로 구성되고, 각 항목은 key/value 두 부분으로 구성됨

주소가 연관 메모리에 있으면 대응되는 프레임 번호를 얻고, 없으면 메모리에 있는 페이지 테이블로부터 프레임 번호를 얻음

<br>

TLB는 페이지 테이블의 일부분만을 저장하는데, CPU가 논리 주소를 생성하면 MMU는 해당 페이지 번호가 TLB에 있는지 확인함

페이지 번호가 발견되면 해당 프레임 번호를 즉시 알 수 있고, 메모리를 접근하는 데 사용

페이징을 사용하지 않는 시스템과 비교하면, 성능 저하는 전혀 없음

<br>

<img width="804" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/a098b958-01a2-440f-824d-fa28a9ab9f8d">

페이지 번호가 TLB에 없을 경우(**TLB miss**), 주소 변환은 앞서 설명했던 단계에 따라 진행됨

👉🏻 페이지 테이블에 대한 메모리 참조가 이루어져야 함

<br>

TLB가 가득 차게 되면, 기존 항목 중 교체될 항목을 선택해야 함

- 교체 정책은 LRU부터 라운드 로빈, 무작위 등 다양한 정책 사용

다른 CPU는 자신이 직접 선택하는데 몇몇 TLB는 특정 항목들을 TLB에 **고정**하면서 TLB에서 제거될 수 없음

👉🏻 중요 커널 코드를 고정

<br>

어떤 TLB는 각 항목에 **ASIDs(Address-Space IDentifiers)** 를 저장하기도 함

그 TLB 항목이 어느 프로세스에 속한 것인지를 알려주며 그 프로세스의 정보를 보호하기 위해 사용

TLB에서 가상 주소를 변환할 때, 현재 수행 주인 프로세스의 ASID가 TLB 항목에 있는 ASID와 같은지 검사함

ASID가 맞지 않으면 ⇒ **miss 처리**

ASID 지원이 있으면 한 TLB 안에 여러 프로세스의 정보를 동시에 함께 보관 가능

**But,** 지원이 없다면 새로운 페이지 테이블이 선택될 때마다 새 프로세스가 다음 실행 프로세스가 잘못 변환하지 않도록 하기 위해서 전부 **플러시(flush)** 가 되어야 함

<br>

**접근하려는 메모리의 페이지 번호가 TLB에서 발견되는 비율**을 **적중률(hit ratio)** 이라 함

<img width="739" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/db170959-86a4-4dab-9c0d-835037843701">

<br>

**실질 메모리 접근 시간(effective memory access time)** 을 계산하기 위해 두 가지 경우에 대해 적중률에 따른 가중치를 적용

<img width="731" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/2356210a-2358-47a2-927c-f31209db09bd">

<br>
<br>

### 3. 보호

페이징 환경에서의 메모리 보호는 각 페이지에 붙어있는 **보호 비트(protection bits)** 에 의해 구현

이 비트들은 보통 페이지 테이블에 속해 있음

<br>

각 비트는 이 페이지가 읽고 쓰기 또는 읽기 전용임을 각각 정의할 수 있는데, 메모리에 대한 모든 접근은 페이지 테이블을 거치므로 주소 변환과 함께 이 페이지에 쓰기가 허용되는지 안 되는지와 같은 검사도 할 수 있음

읽기 전용 페이지에 관해 쓰기를 시도하면 운영체제가 하드웨어로 트랩을 걸어줌

<br>

<img width="810" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/8c561495-5471-453d-b6d4-61fc0834274f">

페이지 테이블의 각 엔트리에는 **유효/무효(valid/invalid)** 라는 하나의 비트가 존재

- 유효(valid) : 페이지가 프로세스의 합법적인 페이지를 나타냄
- 무효(invalid) : 프로세스의 논리 주소 공간에 속하지 않는다는 것을 나타냄

운영체제는 이 비트를 이용해 페이지에 대한 접근을 허용하든지 또는 허용하지 않든지 할 수 있음

ex) 14비트의 주소 공간을 갖는 시스템에서 어느 프로그램은 `0` ~ `10,468` 주소만을 사용할 수 있음

페이지 크기가 `2KB` 일 때 그림과 같은 상황

- 페이지 `0`, `1`, `2`, `3`, `4`, `5` 주소는 페이지 테이블을 통해 정상적으로 사상됨

- `6`, `7` 에서 주소를 매핑하려고 시도하면, 비트가 무효로 설정된 것을 발견해 트랩을 발생시킴

<br>
<br>

프로세스가 자신의 모든 주소 범위를 늘 사용하는 경우는 드물음

많은 프로세스들은 일정한 시각에 단지 일부분만을 집중적으로 사용 👉🏻 모든 페이지에 페이지 테이블 항목을 배정하는 것은 **낭비**

몇몇 시스템은 페이지 테이블의 크기를 나타내기 위해 **페이지 테이블 길이 레지스터(PTLR)**를 제공하고, 프로세스가 제시한 주소가 유효한 범위 내에 있는지를 확인하기 위해 모든 논리 주소 값이 비교됨

이러한 검사에서 오류가 나타난다면 트랩을 발생시킴

<br>
<br>

### 4. 공유 페이지

페이징의 장점은 **공통의 코드를 공유**할 수 있다는 점

일반적인 `Linux` 시스템에서 대부분의 사용자 프로세스는 표준 `C` 라이브러리 `libc`가 필요하고, 각 프로세스 자체 `libc` 사본을 해당 주소 공간에 적재하도록 하는 것

**But,** 코드가 **재진입 코드**인 경우, 다음처럼 공유할 수 있음

<img width="640" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/4c9837de-f78b-4eb9-9810-208d7bf57ca8">

**재진입 코드**는 **자체 수정을 할 수 없는 코드로서 실행 중에는 절대 변경되지 않음**

👉🏻 두 개 이상의 프로세스가 동일한 코드를 동시에 실행할 수 있음

각 프로세스에는 자신의 실행을 위해 데이터를 보유하기 위한 자체 레지스터 사본과 데이터 저장영역이 있는데, 두 프로세스가 가진 데이터는 서로 다를 수 있음

표준 `C` 라이브러리는 물리 메모리에 하나의 사본만 저장하면 되고, 각 사용자가 프로세스의 페이지 테이블은 동일한 물리적 사본으로 매핑시킴

<br>

`libc` 와 같은 실행 시간 라이브러리 외에도 컴파일러, 윈도 시스템, 데이터베이스 시스템 등과 같이 많이 사용되는 다른 프로그램도 공유할 수 있음

<br>
<br>

> *페이지를 통한 메모리 관리는 같은 물리 페이지 프레임을 여러 프로세스가 공유한다는 것 뿐만 아니라 다양한 이익을 가져다 줌*
>

<br>
<br>

## 💭 페이지 테이블의 구조

### 1. 계층적 페이징

현대 컴퓨터는 매우 큰 주소 공간(`2^32` ~ `2^64`)을 가지며, 이러한 환경에서 페이지 테이블도 상당히 커짐

ex) `32` 비트 논리 주소 공간을 가진 시스템을 생각해보자

페이지 크기가 `4KB` 라면, 페이지 테이블은 100만개 이상의 항목으로 구성되며, 각 항목은 `4B` 로 구성되므로 각 프로세스는 페이지 테이블만을 위해서도 `4MB` 의 공간이 필요함

이러한 경우 모든 페이지 테이블을 메인 메모리에서 연속적으로 할당 ❌

한 가지 방법은 **페이지 테이블을 여러 개의 작은 조각으로 나누는 것**

<br>

**2단계 페이징 기법(two-level paging scheme)** 으로 페이지 테이블 자체가 다시 페이징되게 하는 과정

<img width="665" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/135ec56e-b09f-49b9-92de-b9fbfd05a850">

<br>

ex) 앞서 들었던 예를 다시 한 번 들어보자

<img width="846" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6e8a106d-b613-40de-aecd-5a08b0f3049c">

논리 주소는 `20` 비트짜리 페이지 번호와 `12` 비트짜리 페이지 오프셋으로 이루어짐

이 방식에서는 주소 변환이 바깥 페이지 테이블에서 시작해 안쪽으로 들어오므로 이 방식을 **forward-mapped 페이지 테이블**이라고도 부름

<br>

`64` 비트 논리 주소 공간을 가진 시스템에서는 사실 **2단계 페이징 기법도 적절지 못함**

<img width="846" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6e8a106d-b613-40de-aecd-5a08b0f3049c">

다음 단계는 2번째 바깥 테이블 자체를 페이징하는 등의 4단계 페이징 기법을 사용할 수 있을 것임

`64` 비트 `UltraSPARC` 구조는 7단계 페이징을 해야 하며, 각 논리 주소를 사상하기 위해 **너무 많은 메모리 접근을 필요로 하기 때문에 비현실적**

***👉🏻 일반적으로 `64` 비트 구조에서는 계층적 테이블이 부적합하다는 것을 알 수 있음***

<br>
<br>

### 2.해시 페이지 테이블

주소 공간이 `32` 비트보다 커지면 가상 주소를 해시로 사용하는 **해시 페이지 테이블**을 많이 사용함

해시 테이블의 각 항목은 연결 리스트를 갖고 있는데, 충돌을 일으켜 모두 이곳으로 해시되는 원소들이 매달리게 됨

이때, 각 원소는 세 개의 필드를 지님

*1) 가상 페이지 번호*

*2) 사상되는 페이지 프레임 번호*

*3) 연결 리스트상의 다음 원소 포인터*

<br>

여기서 알고리즘은 다음과 같이 작동됨

가상 주소 공간으로부터 페이지 번호가 오면 해싱 후, 해시 페이지 테이블에서 연결 리스트를 따라가며 첫 번째 원소와 가상 페이지 번호를 비교

일치되면 대응하는 페이지 프레임 번호를 가져와 물리 주소를 얻을 수 있고, 일치되지 않다면 연결 리스트의 그 다음 원소로 똑같은 일을 반복 수행

<img width="767" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/c8ef0e9c-2e28-421d-819d-31db33f9749d">

<br>

`64`비트 시스템에서 유용하도록 변형된 해시 테이블 기법이 제안되었음

이 변형 기법은 해시 테이블과 비슷한 **클러스터 페이지 테이블**을 사용

해시 페이지 테이블의 각 항목이 한 개의 페이지만 가리키는 것에 반해, 클러스터 페이지 테이블의 각 항목은 여러 페이지를 가리킴

<br>
<br>

### 3. 역 페이지 테이블

보통 프로세스는 각자 하나씩 페이지 테이블을 갖고 페이지 테이블은 프로세스가 사용하는 페이지마다 하나의 항목을 지님

운영체제는 프로세스가 가상 페이지 주소를 제시할 때마다 이 테이블에 와서 그것을 실제 페이지 주소로 변환시켜 주어야 함

이 기법의 단점 중 하나는 **각 페이지 테이블 항목의 개수가 수백만 개가 될 수 있음**

👉🏻 물리 메모리의 사용을 추적하기 위해 **많은 양의 물리 메모리를 소비**함

<br>

**🙌🏻 해결방법**

**✅ 역 페이지 테이블(inverted page table)**

<img width="754" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/12f05b0d-e7a1-42d6-9157-5f29e8b1b7e0">

메모리 프레임마다 한 항목씩을 할당

각 항목은 그 프레임에 올라와 있는 페이지 주소, 그리고 그 페이지를 소유하고 있는 프로세스의 ID를 표시하고 있음

이렇게 되면 시스템에는 단 하나의 페이지 테이블만이 존재하게 되고, 테이블 내 각 항목은 메모리 한 프레임씩을 가리키게 됨

역 페이지 테이블은 종종 각각의 페이지 테이블 엔트리에 저장되는 주소 공간 ID를 요구

- 테이블은 보통 물리 공간을 사상하는 서로 다른 주소 공간이 혼재하고 있기 때문

주소 공간 ID를 저장함으로써 특정 프로세스의 논리 페이지가 그에 상응하는 물리 페이지 프레임과 사상되었다는것을 보장

<br>

각각의 역 페이지 테이블의 엔트리는 `<process-id, page-number>` 의 쌍으로 이루어져 있음

- `process-id` : 주소 공간 ID의 역할

메모리 참조가 발생하면, `<process-id, page-number>` 의 쌍으로 이루어진 가상 주소의 일부가 메모리 하부 시스템에 전달됨

역 페이지 테이블에서 일치하는 것이 있는지 검색하고, `i` 번째 엔트리에서 발견되면 물리 주소는 `<i,offset>` 이 되고, 일치하는 것이 없다면 잘못된 메모리 접근으로 간주

<br>
<br>

이 방법은 논리 페이지마다 항목을 갖는 대신 물리 프레임에 대응되는 항목만 테이블에 저장하기 때문에, 메모리에서 훨씬 작은 공간을 점유함

**But,** 다른 한편 역페이지 테이블은 **주소 변환 시간이 더 오래 걸릴 수 있음**

역 페이지 테이블은 물리 주소에 따라 정렬되어 있고, 탐색은 가상 주소를 기준으로 하므로 테이블 전체를 탐색해야 할 수도 있음 👉🏻 이 탐색은 매우 오래 걸리게 됨

<br>
<br>

## 💭 스와핑

<img width="756" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/683aefc2-263b-4704-8744-5f5271ac02d6">


프로세스가 실행되기 위해서는 프로세스의 명령어와 명령어가 접근하는 데이터가 메모리에 있어야 함

**But,** **프로세스는 실행 중에 임시로 백업 저장장치(backing store)로 내보내어 졌다가 실행을 계속하기 위해 다시 메모리도 되돌아 올 수 있음**

모든 프로세스의 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리 크기보다 큰 경우에도 스와핑을 이용하면 동시에 실행하는 것이 가능해 **다중 프로그래밍의 정도를 증가**시킴

<br>
<br>

### 1. 기본 스와핑

표준 스와핑에는 메인 메모리와 백업 저장장치 사이에서 프로세스를 이동시킴

- 백업 저장장치 : 모든 사용자들의 모든 프로세스를 수용할 만큼 크고 빠른 디스크

프로세스 또는 일부가 백업 저장장치로 스왑될 때 프로세스와 관련된 자료구조는 백업 저장장치에 기록되어야 함

다중 스레드 프로세스의 경우, 모든 스레드당 데이터 구조도 스왑되어야 함

또한 운영체제는 스왑 아웃된 프로세스에 대해 메타 데이터를 유지해야 메모리로 다시 스왑 인될 때 복원될 수 있음

<br>

**프로세스를 스왑**하려면, 그 프로세스는 **완전히 휴지 상태**에 있어야 함

프로세스가 **입출력 장치와 신호를 주고 받는 동안**이라면 **스왑해서는 안됨**

<br>
<br>

> ***표준 스와핑**에서는 실제 물리 메모리보다 더 많은 프로세스를 수용할 수 있도록 **물리 메모리가 초과 할당될 수 있다는 장점**을 지니고 있음*
>

### 2. 페이징에서의 스와핑

표준 스와핑은 메모리와 백업 저장장치 간에 프로세스 전체를 이동하는 데 걸리는 시간이 엄청나기 때문에, 일반적으로 **최신 운영체제에서는 더는 사용되지 않음**

<img width="481" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6078bf9a-ad10-4134-8be8-3d75a694eb78">

`Linux` 및 `Windows` 를 포함한 대부분의 시스템은 프로세스 전체가 아닌 프로세스 페이지를 스왑할 수 있는 변형 스와핑을 사용함

물리 메모리를 초과 할당할 수 있지만, **프로세스 전체를 스왑하는 비용은 발생 ❌**

👉🏻 단지, 적은 수의 페이지만 스왑에 관여

실제로 ***스와핑*** 이란 용어는 일반적으로 표준 스와핑을 말하며, ***페이징*** 은 페이징에서의 스와핑을 말함

<br>

**페이지 아웃 연산**은 페이지를 메모리에서 백업 저장장치로 이동시킴

반대 방향의 연산을 **페이지 인 연산**이라고 함

페이징에서의 스와핑은 가상 메모리와 함께 잘 작동함

<br>
<br>

### 3. 모바일 시스템에서의 스와핑

PC와 서버 대부분의 운영체제는 페이지 스와핑을 지원함

**But, 모바일 시스템은 어떤 형태의 스와핑도 지원하지 않는 것**이 일반적

*1)iOS*

- 스와핑 사용 대신 자유 메모리가 정해진 임계 값보다 떨어지면 응용에 할당된 메모리를 자발적으로 반환하도록 요청
- 스택과 같은 변경된 데이터는 절대 제거될 수 없음
- 충분한 메모리를 반환하지 못한 응용은 운영체제에 의해 종료될 수 있음

*2)Android*

- iOS와 유사한 정책을 채택하며, 자유 메모리가 부족하면 프로세스를 종료시키는 것이 가능
- 프로세스를 종료하기 전 응용의 상태를 플래시 메모리에 저장해 나중에 빠르게 재시작 가능

<br>
<br>

> *이러한 제약 사항들 때문에 모바일 운영체제 개발자들은 응용이 너무 많은 메모리를 사용하거나 또는 메모리 누수로 고생하지 않도록 주의해서 메모리를 할당하고 반환해야 함*
>