# Chapter 09 메인 메모리

## 💭 배경

📢 ***메인 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할***

<br>
메모리는 각각 주소가 할당된 일련의 바이트들로 구성

CPU는 PC가 지시하는 대로 메모리부터 다음 수행할 명령어를 가져오는데, 그 명령어는 필요한 경우 추가적인 데이터를 더 가져올 수 있으며, 반대로 데이터를 메모리로 내보낼 수도 있음

<br>
<br>

### 1. 기본 하드웨어

메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치

기계 명령어들은 메모리 주소만을 인수로 취하고, 디스크의 주소를 인수로 취하지 않음

👉🏻 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 **메인 메모리**와 **레지스터**에 있어야 함

if) 데이터가 메모리에 없다면 ? ⇒ **CPU가 처리하기 전 메모리로 이동**시켜야 함

<br>

각 CPU 코어에 내장된 레지스터들은 일반적으로 **CPU 클록의 1사이클 내에 접근 가능**

일부 처리 코어들은 레지스터에 있는 명령어의 해독과 간단한 연산을 클록 틱(clock tick)당 하나 또는 그 이상의 속도로 처리함

- clock tick : CPU의 클럭 신호가 한 번 발생하는 시간 간격을 의미, 이 시간 간격동안 CPU는 작업을 수행

<br>

**But,** 메모리 버스를 통해 전송되는 메인 메모리의 경우는 앞에서 언급했던 상황과는 다름

메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요되며, 이 경우 **CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연**되는 **stall 현상**이 발생하게 됨

<br>

**🙌🏻 해결방법**

**✅** CPU와 메인 메모리 사이에 빠른 속도의 메모리를 추가

**✅** CPU에 구축된 캐시를 관리해 하드웨어는 어떠한 운영체제의 도움 없이 메모리 접근 속도를 향상

<br>
<br>

물리 메모리의 상대적인 접근 속도의 차이를 고려하는 것에 추가로 올바른 동작을 보장해야만 함

시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐 아니라, 사용자 프로그램 사이도 서로 보호해야 함

**운영체제가 CPU와 메모리 간 접근 중에 개입하게 되면 성능이 떨어지기 때문에** 이러한 보호 기법은 반드시 **하드웨어가 지원**해야 함

![image](https://github.com/SeoYunnn/TIL/assets/120713987/65067188-f4b9-426f-8ef0-a5b9b4e4a2a3)

<br>

먼저 각각 프로세스가 독립된 메모리 공간을 가지도록 보장해야 함

개별적인 프로세스 별 메모리 공간은 서로를 보호하고, 병행 실행을 위해 여러 프로세스가 메모리에 적재되게 하는 것이 필수적임

개별적 메모리 공간을 분리하기 위해 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 설정하고, 프로세스가 합법적인 영역만을 접근하도록 하는 것이 필요

그림처럼, **기준(base)** 과 **상한(limit)** 이라고 불리는 두 개의 레지스터를 활용해 보호 기법을 제공

- 기준 레지스터 : 가장 작은 합법적인 물리 메모리 주소의 값을 저장
- 상한 레지스터 : 주어진 영역의 크기를 저장

ex) 기준 레지스터 값이 `300040` 이고, 상한 레지스터의 값이 `120900` 이라면 프로그램은 `300040`~`420940` 까지 모든 주소를 접근 가능

![image](https://github.com/SeoYunnn/TIL/assets/120713987/ab070a86-3d8b-4d9b-81af-5aa54447d662)

<br>

메모리 공간의 보호는 CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어짐

사용자 모드에서 수행되는 프로그램이 운영체제의 메모리 공간이나 다른 사용자 프로그램의 메모리 공간에 접근하면 운영체제는 치명적인 오류로 간주하고, **trap**을 발생시킴

사용자 프로그램이 우연히든, 의도적이든 간에 운영체제나 **다른 사용자 프로그램의 코드나 데이터 구조를 수정하는 것을 막음**

<br>

기준과 상한 레지스터는 여러 가지 **특권 명령(special privileged instruction)** 을 사용하는 운영체제에 의해서만 **적재(load)** 됨

오직 커널 모드에서 수행되기 때문에 **운영체제만 레지스터들의 값을 변경할 수 있도록 허가**해 줌으로써 **사용자 프로그램이 레지스터의 내용을 변경하는 것을 막음**

<br>

커널 모드에서 수행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지 않음

운영체제는 사용자 프로그램을 사용자 메모리 영역의 적재, 오류가 발생한 경우에 그 프로그램을 덤프(dump out), 시스템 콜의 매개변수를 변경, 사용자 메모리로부터의 입출력과 다른 많은 서비스를 제공할 수 있음

ex) 다중 처리기 시스템 운영체제는 한 프로세스의 상태를 레지스터로부터 메인 메모리로 저장하고, 다음 프로세스의 문맥을 메인 메모리로부터 레지스토로 저장하는 문맥 교환을 반드시 실행해야 함

<br>
<br>

### 2. 주소의 할당

프로그램은 원래 이진 실행 파일 형태로 디스크에 저장되어 있기 때문에 실행하기 위해선 프로그램을 메모리로 가져와서 프로세스 문맥 내에 배치해야 함

이 시점에 가용한 CPU에서 실행할 수 있게 되는데, 프로세스가 실행되면 메모리에서 명령 및 데이터에 엑세스 함

결국 프로세스가 종료되고 다른 프로세스에서 사용하기 위해 메모리가 회수됨

<br>

대부분 시스템은 사용자 프로세스가 메모리 내 어느 부분으로도 올라올 수 있도록 지원하고 있음

사용자 프로세스의 주소가 `00000` 번지부터 시작된다고 해서 굳이 `00000` 번지부터 올라와야 할 필요는 없음

대부분의 경우 사용자 프로그램은 다음과 같이 여러 단계를 거쳐 실행되기 때문에 이들 단계를 거치는 동안 주소들은 여러 가지 다른 표현 방식을 거치게 됨

![image](https://github.com/SeoYunnn/TIL/assets/120713987/39395045-6f59-4716-8aff-be8398923d88)

**1️⃣ 컴파일 시간(compile time) 바인딩**

- 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대 코드**를 생성할 수 있음
    - 절대 코드 : 프로그램이 메모리에 로드될 때 주소가 정적으로 할당되어 있는 코드를 의미

ex) 사용자 프로세스가 `R` 번지로부터 시작한다는 것을 미리 알 수 있다면 컴파일러는 번역할 코드를 그 위치에서 시작해 나가지만 위치가 변경되어야 한다면 다시 컴파일 되어야 함

<br>
<br>

**2️⃣ 적재 시간(load time) 바인딩**

- 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면, 컴파일러는 일단 이진 코드를 **재배치 가능 코드**로 만들어야 함
- 이 경우 심볼과 진짜 번지수와의 바인딩은 프로그램이 메인 메모리로 실제로 적재되는 시간에 이루어지게 됨
- 재배치 가능 코드는 시작 주소가 변경되면, 아무 때나 사용자 코드를 다시 적재하기만 하면 됨

<br>
<br>

**3️⃣ 실행 시간(execution time) 바인딩**

- 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있다면, 바인딩이 실행 시간까지 허용되었다고 이야기 함
- 이런 것이 가능해지려면 특별한 하드웨어를 이용해야 함

<br>
<br>

### 3. 논리 대 물리 주소 공간

CPU가 생성하는 주소를 일반적으로 **논리 주소(logical address)** 라 하며, 반면에 메모리가 취급하게 되는 주소 즉, **메모리 주소 레지스터(MAR)** 에 주어지는 주소는 일반적으로 **물리 주소(physical address)** 라 함

<br>

컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같음

**But,** 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다름 👉🏻 논리 주소를 **가상 주소(virtual address)** 라 함 

프로그램에 의해 생성된 모든 논리 주소 집합을 **논리 주소 공간(logical address space)** 이라 하며, 이 논리 주소와 일치하는 모든 물리 주소 집합을 **물리 주소 공간(physical address space)** 이라 함

![image](https://github.com/SeoYunnn/TIL/assets/120713987/91b0bda9-f495-4a65-a7e8-ef6dbe21e6ba)

<br>

프로그램의 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꿔줘야 하는데, 이 변환(mapping) 작업은 하드웨어 장치인 **메모리 관리 장치(MMU)**에 의해 실행됨

변환을 수행하기 위해 여러 가지 방법 중에서 선택할 수 있는데, 우선 여기에서는 기준 레지스터(base register) 기법을 일반화시킨 아주 단순한 MMU기법에 따른 변환을 설명

![image](https://github.com/SeoYunnn/TIL/assets/120713987/2c015c51-8bb5-44d9-ac53-c6bc97ff918f)

기준 레지스터를 **재배치(relocation) 레지스터**라 부름

재배치 레지스터 속에 들어있는 값은 주소가 메모리로 보내질 때마다 그 모든 주소에 더해짐

<br>

**사용자 프로그램은 절대로 실제적 물리 주소에 접근하지 않음**

사용자 프로그램은 `364` 번지에 대한 포인터를 생성해서 그것에 대해 저장, 연산, 다른 주소들과 비교하는 등 온갖 일을 할 수 있지만 그것이 주소(간접 적재 및 저장)로 갈 때는 기준 레지스터에 대해 다시 바인딩 됨

사용자 프로그램은 논리 주소를 사용한 것이고, 메모리 하드웨어는 논리 주소를 실제 주소로 바꾼 것

참조된 메모리 주소의 실제 위치는 이 참조가 실제 실행 시간에 결정됨

<br>

이제는 두 가지 주소, 즉 논리 주소(`0` ~ `max` 까지 범위)와 실제 주소(기준값 R에 대해 `R+0` 에서 `R+max` 까지 범위)가 있다는 사실에 주의해야 함

<br>
<br>

### 4. 동적 적재

📢 ***메모리 공간의 더 효율적 이용을 위해서는 동적 적재(dynamic loading)를 해야 함***

<br>

**동적 적재**에서 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않고, 재배치 가능한 상태로 디스크에서 대기하고 있음

먼저 `main` 프로그램이 메모리에 올라와 실행됨

이 루틴이 다른 루틴을 호출하게 되면 호출된 루틴이 이미 메모리에 적재됐는지를 조사함

if) 적재되어 있지 않다면 ? ⇒ **재배치 가능 연결 적재기(relocatable linking loader)** 가 불려 요구된 루틴을 메모리로 가져오고, 테이블에 기록

<br>
<br>

> ***동적 적재**는 루틴이 필요한 경우에만 적재된다는 점에서 이점을 지니며, 오류 처리 루틴처럼 아주 간혹 발생하면서도 실행할 코드가 많은 경우에 특히 유용함*
>

<br>
<br>

### 5. 동적 연결 및 공유 라이브러리

📢 ***동적 연결 및 공유 라이브러리(DLL) : 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리***

<br>

어떤 운영체제는 **정적 연결(static linking)** 만을 지원하는데, 이 경우에는 라이브러리가 이 프로그램의 이진 프로그램 이미지에 끼어 들어가게 됨

**But,** **동적 연결 개념은 동적 적재의 개념과 유사**함

<br>

**동적 적재에서는 로딩(loading)이 실행 시까지 미루어졌었지만, 동적 연결에서는 연결(linking)이 실행 시기까지 미루어지는 것**

동적 연결은 주로 표준 `C` 언어 라이브러리와 같은 시스템 라이브러리에 사용됨

이 기능이 없으면 시스템의 각 프로그램은 실행 가능 이미지에 해당 언어 라이브러리의 사본을 포함해야 함

👉🏻 이 요구 사항은 **실행 가능 이미지의 크기를 증가**시킬 뿐 아니라 **메인 메모리를 낭비**할 수도 있음

<br>

또한, DLL은 라이브러리를 여러 프로세스 간에 공유할 수 있어, 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있음

👉🏻 공유 라이브러리라고도 하며, `Windows` 및 `Linux` 시스템에서 광범위하게 사용

<br>

프로그램이 동적 라이브러리에 있는 루틴을 참조하면 로더는 DLL을 찾아 필요한 경우 메모리에 적재

그 후 다음 동적 라이브러리의 함수를 참조하는 주소를 DLL이 저장된 메모리의 위치로 조정

<br>
<br>

동적 연결 라이브러리는 라이브러리 갱신으로(버그 수정 등) 확장할 수 있으며, 언제나 새로운 버전으로 교체될 수 있음 👉🏻 해당 라이브러리를 사용하는 모든 프로그램은 자동으로 새로운 라이브러리 버전을 사용하게 될 것

if) 동적 연결이 없었다면 ? ⇒ 새로운 라이브러리를 사용하기 위해 **모든 프로그램은 새로 링크** 되어야 함

<br>
<br>

> *동적 적재와는 달리 **동적 연결과 공유 라이브러리는 일반적으로 운영체제의 도움이 필요**
메모리에 있는 프로세스들의 각자 공간이 자신만 액세스 할 수 있도록 보호 된다면 **운영체제만이 기억 공간에 루틴이 있는지를 검사할 수 있고, 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록** 해줄 수 있음*
>

<br>
<br>

## 💭 연속 메모리 할당

메모리는 일반적으로 두 개의 부분으로 나뉨

*1) 운영체제를 위해*

*2) 사용자 프로세스를 위해*

<br>

일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하기를 원함 👉🏻 메모리에 적재되기를 기다리는 프로세스에 사용 가능한 메모리를 할당하는 방법을 고려

연속적 메모리 할당에서 각 프로세스는 다음 프로세스가 적재된 영역과 인접한 하나의 메모리 영역에 적재됨

**But,** 앞서 **메모리 보호 문제를 해결**해야 함

<br>
<br>

### 1. 메모리 보호

![image](https://github.com/SeoYunnn/TIL/assets/120713987/baa8f991-8ae6-4fc4-9d15-9e37f99bf71d)

<br>

재배치 레지스터는 가장 작은 물리 주소의 값을 저장하고, 상한 레지스터는 논리 주소의 범위 값을 저장

각각의 논리 주소는 상한 레지스터가 지정한 범위 안에 존재해야 함

MMU는 동적으로 논리 주소에 재배치 레지스터의 값을 더함으로써 주소를 변환하는 역할을 하는데, 변환된 주소는 메모리로 보내짐

<br>

CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때, **디스패처(dispatcher)** 는 **재배치 레지스터와 상한 레지스터에 정확한 값을 적재**함

CPU에 의해서 생성되는 모든 주소는 레지스터들의 값을 참조해서 확인 작업을 거치기 때문에, 운영체제와 다른 사용자 프로그램을 현재 수행 중인 사용자 프로그램의 접근으로부터 보호 가능

<br>
<br>

> *재배치 레지스터를 사용함으로써 운영체제의 크기는 실행 중이라도 얼마든지 변경될 수 있으며 매우 유용하게 쓰일 수 있음
ex) 장치 드라이버가 더 필요하지 않은 경우 장치 드라이버를 제거하고 메모리를 다른 요청에 할당할 수 있음*
>

<br>
<br>

### 2. 메모리 할당

메모리 할당하는 가장 간단한 방법 중 하나는 프로세스를 메모리 가변 크기 파티션에 할당하는 것

각 파티션에는 정확히 하나의 프로세스만 적재 가능

<br>

**가변 파티션 기법**에서 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지함

처음에는 모든 메모리가 사용자 프로세스에 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록인 **hole** 로 간주

- hole : 할당되지 않은 메모리 영역을 말함 👉🏻 사용 가능한 메모리 블록 중에서 **프로세스에 할당되지 않은 부분**

![image](https://github.com/SeoYunnn/TIL/assets/120713987/0a4264dd-32ba-4bf9-a769-7731200d6afa)

<br>

**◎ 9.7 설명**

처음에는 프로세스 `5`, `8`, `2` 가 적재되어 있고 메모리가 완전히 활용 상태

프로세스 `8` 이 종료된 후 하나의 연속된 hole 이 생김

나중에 프로세스 `9` 가 도착하고 메모리가 할당

프로세스 `5` 가 종료되면 두 개의 연속되지 않은 hole 생성

<br>
<br>

프로세스가 시스템에 들어오면 운영체제는 각 프로세스가 메모리를 얼마나 요구하며, 또 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려해 공간을 할당함

프로세스가 공간을 할당받게 되면, 이후로는 CPU를 할당받기 위해 경쟁

<br>

**🤔 도착 프로세스의 요구를 충족시키기에 메모리가 충분하지 않으면 어떻게 되는가 ?**

*1) 단순히 프로세스를 거부하고 적절한 오류 메세지를 제공*

*2) 메모리가 나중에 해제되면 운영체제는 대기 큐를 검사해 대기 프로세스의 메모리 요구를 충족시킬지 여부를 결정*

<br>
<br>

일반적으로 메모리에는 다양한 크기의 hole 이 여기저기 산재하게 되는데 **프로세스에 공간이 필요할 때 운영체제는hole의 집합에서 적절한 것을 찾아내야 함**

찾은 hole이 요청한 것보다 약간 크면 두 개로 나누어 한 조각은 프로세스에 할당하고, 나머지 하나는 hole 집합으로 되돌아감

그 프로세스가 끝나면 공간은 hole의 집합으로 되돌아가고, 새로운 hole이 다른 hole과 인접해 있다면, 이 두 개의 블록을 합쳐서 한 개의 큰 hole로 만들음

<br>

이러한 기법은 **“동적 메모리 할당 문제”** 의 특별한 예시 중 하나

일련의 가용 공간-리스트로부터 크기 n-바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제

즉, **메모리 할당 알고리즘이 어떻게 효율적으로 메모리를 할당할지 결정하는 문제**

<br>

**🙌🏻 해결방법**

- **최초 적합(first fit)**
    - 첫 번째 사용 가능한 가용 공간 할당
    - 검색은 집합의 시작에서부터 하거나 검색이 끝났던 곳에서 시작될 수 있음
    - 충분히 큰 가용 공간을 찾았을 경우 검색을 끝낼 수 있음
- **최적 적합(best fit)**
    - 사용 가능한 공간 중 가장 작은 것을 택함
    - 리스트가 크기 순으로 되어 있지 않다면 전 리스트를 검색해야만 함
    - 아주 작은 가용 공간을 만들어냄
- **최악 적합(worst fit)**
    - 가장 큰 가용 공간을 택함
    - 할당해 주고 남는 가용 공간은 충분히 크기에 다른 프로세스들을 위해 유용하게 사용 가능
    - 이때, 가용 공간들이 크기 순으로 정렬되어 있지 않으면 전 리스트를 다 검색해야 함

<br>
<br>

> *모의실험을 통해 연구했을 때, **최초 적합과 최적 적합 모두 시간과 메모리 이용 효율 측면에서 최악 적합보다 좋다**는 것이 입증되었음
공간 효율성 측면에서는 어느 것이 항상 더 좋다고 말할 수는 없지만 **최초 적합이 일반적으로 속도가 더 빠름***
>

<br>
<br>

### 3. 단편화

**♦︎ 외부 단편화**

최초 적합, 최적 적합 전략 모두 **외부 단편화(external fragmentation)** 로 인해 문제를 겪음

프로세스들이 메모리에 적재되고 제거되는 일이 반복되면 어떤 가용 공간은 너무 작은 조각이 됨

외부 단편화는 **유휴 공간들을 모두 합치면 충분한 공간이 되지만 너무 작은 조각들로 여러 곳에 분산되어 있을 경우 발생**

👉🏻 메모리는 너무 많은 수의 매우 작은 조각들로 단편화되어 있음

👉🏻 최악의 경우로는 **모든 프로세스 사이마다 못 쓰게 된 가용 공간을 가질 수 있음**

<br>

메모리의 전체 크기와 프로세스 크기들은 모두 외부 단편화에 따라 큰 영향을 미칠 수 있음

ex) 최초 적합의 경우 `N` 개 블록이 할당되었을 때 `0.5N` 개 블록이 단편화 때문에 손실될 수 있다는 것을 알 수 있음

*👉🏻* ***50% 규칙**(절반 이상이 외부 단편화로 인해 손실)*

<br>
<br>

**♦︎ 내부 단편화**

내부적으로도 단편화가 발생할 수 있는데, 그에 대한 예시를 살펴보자

`18,464B` 크기의 가용 공간을 생각했을 때, 어느 한 프로세스가 `18,462B` 를 요구한다고 가정해보자

요구된 블록을 정확히 할당하면 `2B` 의 가용 공간이 남게 되는데, 가용 공간을 놓치지 않기 위해 오히려 더 큰 부담을 시스템이 가지게 될 수 있음

일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고, 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수배로만 해주는 것이 보통의 경우

**But,** 예시된 경우에서는 할당된 공간이 요구된 공간보다 약간 더 클 수 있음

👉🏻 두 크기 사이의 남는 부분이 ***“내부 단편화(internal fragmentation)”***

<br>
<br>

**🙌🏻 해결방법**

✅ **압축(compaction)**

👉🏻 메모리 모든 내용을 한 군데로 몰고 모든 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만드는 방법

<br>

**But,** 항상 압축이 가능한 것은 아님

재배치가 어셈블 또는 적재 시에 정적으로 행해진다면, 압축은 실행될 수 없음

압축은 프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만 가능

주소가 동적으로 재배치할 수 있다면, 재배치 작업은 프로그램과 데이터를 새로운 위치로 옮기고 새 위치를 반영하기 위해 기준 레지스터만 변경하면 완료됨

압축이 가능하더라도 그 비용을 검토해봐야 함

<br>

가장 간단한 압축 알고리즘은 단순히 모든 프로세스를 한쪽 끝으로 이동시켜 모든 가용 공간이 그 반대 방향으로 모이도록 하는 방법이지만 비용이 너무 많이 들음

<br>

**✅ 페이징(paging)**