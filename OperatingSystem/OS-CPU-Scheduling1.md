# Chapter 05 CPU 스케줄링

## 💭 CPU 스케줄링이란 ?
📢 ***CPU 스케줄링 : 프로세스가 작업을 수행할 때, 언제 어떤 프로세스에 CPU를 할당할 지를 결정하는 작업
<br> ✔️ 운영체제가 CPU를 효율적으로 활용하기 위한 방법
<br> ✔️ 여러 프로세스들 중 어떤 프로세스를 먼저 실행할 지, 얼마나 오랫동안 실행할 지를 결정하는 일련의 과정***

<br>
<br>

### 1. CPU-I/O 버스트 사이클

CPU 스케줄링의 성공은 프로세스들의 다음과 같은 관찰된 성질에 의해 구분됨

- **CPU 실행**
- **I/O 대기 사이클**

프로세스들은 이들 두 상태 사이를 교대로 이동함

프로세스 실행은 CPU 버스트로 시작되고, 그 후 I/O 버스트가 발생하고, 잇따라 또 다른 CPU 버스트가 발생하고 또 다른 I/O 버스트로 진행

마지막 CPU 버스트는 또 다른 I/O 버스트가 뒤따르는 대신, 실행을 종료하기 위해 시스템 요청과 함께 끝남

<img width="586" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/f88138b9-8094-4842-be72-f37a138e3cb8">

<img width="628" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/7d8802e1-a68d-436b-ab8a-c464309d6fc0">

CPU 버스트들의 지속 시간을 측정한 결과 이들은 프로세스나 컴퓨터마다 변화가 크지만, 그림처럼 유사한 빈도수 곡선을 갖는 경향이 있음

짧은 CPU 버스트가 많이 있고 긴 CPU 버스트는 적음

I/O 중심의 프로그램은 전형적으로 짧은 CPU 버스트를 많이 가질 것이라고 예상됨

CPU 지향 프로그램은 다수의 긴 CPU 버스트를 가질 수 있는데 이러한 분포는 CPU 스케줄링 알고리즘을 구현할 때 매우 중요할 수 있는 사항

<br>
<br>

### 2. CPU 스케줄러

CPU가 유휴 상태가 될 때마다, 운영체제는 준비 큐에 있는 프로세스 중 하나를 선택해 실행

선택 절차는 CPU 스케줄러에 의해 수행되는데, 스케줄러는 실행 준비가 되어 있는 메모리 내의 프로세스 중에서 선택해 이들 중 하나에게 CPU를 할당

<br>

**준비 큐**는 **반드시 선입선출(FIFO) 방식의 큐가 아니어도 되는 것에 유의**해야 함

여러 가지 스케줄링 알고리즘들을 고려할 때 알게 되겠지만, **준비 큐**는 **선입선출 큐, 우선순위 큐, 트리 또는 단순히 순서가 없는 연결리스트**로 구현할 수 있음

**But,** 개념적으로는 준비 큐에 있는 모든 프로세스가 CPU에서 실행할 차례를 기다리며 줄을 서 있는 것으로 생각할 수 있음

큐 안에 있는 레코드는 일반적으로 프로세스의 PCB로 구성되어 있음

<br>
<br>

### 3. 선점 및 비선점 스케줄링

CPU 스케줄링 결정은 네 가지 상황에서 발생할 수 있음

***1) 한 프로세스가 실행 상태에서 대기 상태로 전환***

- ex) I/O 요청이나 자식 프로세스가 종료되기를 기다리기 위해 `wait()` 를 호출할 때

<br>

***2) 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때***

- ex) 인터럽트가 발생

<br>

***3) 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때***

- ex) I/O 종료

<br>

***4) 프로세스가 종료할 때***

상황 1, 4의 경우에는 스케줄링 면에서는 선택의 여지가 없음

실행을 위해 새로운 프로세스(준비 큐에 하나라도 존재할 경우)가 반드시 선택되어야 함

반면, 상황 2, 3은 선택의 여지가 있음

<br>

상황 1과 4에서만 스케줄링이 발생할 경우에는 ***“비선점”*** 또는 ***“협조적”*** 이라 함

그렇지 않은 상황이라면 ***“선점”*** 이라 함

비선점 스케줄링에서는, CPU가 한 프로세스에 할당되면 프로세스가 종료하든지 또는 대기 상태로 전환해 CPU를 방출할 때까지 점유함

- `Windows`, `macOS`, `Linux` 및 `UNIX` 를 포함한 거의 모든 최신 운영체제들은 선점 스케줄링 알고리즘을 사용함

<br>

**But, 선점 스케줄링**은 데이터가 다수의 프로세스에 의해 공유될 때 **경쟁 조건을 초래할 수 있음**

또한 **운영체제 커널 설계에 영향**을 미침

시스템 콜을 처리할 동안, 커널은 한 프로세스를 위한 활동(I/O 큐와 같은)으로 바쁠 수 있음

이런 활동은 중요한 커널자료 변경을 포함할 수 있는데 변경 도중에 해당 프로세스가 선점되고 커널이 동일한 구조를 읽거나 변경할 필요가 있으면 지속적으로 혼란이 야기될 수 있음

<br>

운영체제 커널은 선점 또는 비선점 방식으로 설계될 수 있음

비선점형 커널은 문맥 교환을 하기 전 시스템 콜이 완료되거나 입출력 완료를 기다리며 프로세스가 봉쇄되기를 기다림

커널 자료구조가 비일관적인 상태에 있을 때 커널이 해당 프로세스를 선점하지 않기 때문에, 이런 방법은 커널 구조를 단순하게 만들음

😡 이러한 커널 실행 모델은 **주어진 시간 안에 태스크의 실행이 완료되어야 하는 실시간 컴퓨팅을 지원하기에는 좋은 모델이 아님**

<br>

선점형 커널에는 공유 커널 데이터 구조에 액세스 할 때 경쟁 조건을 방지하기 위해 mutex 락과 같은 기법 필요

대부분 최신 운영체제는 이제 커널 모드에서 실행될 때 완전히 선점될 수 있음

<br>

인터럽트는 어느 시점에서건 일어날 수 있고, 커널에 의해서 항상 무시될 수는 없기 때문에 인터럽트에 의해서 영향을 받는 코드 부분은 반드시 동시 사용으로부터 보호되어야 함

운영체제는 거의 항상 인터럽트를 받아들일 필요가 있는데, 그렇지 않으면 입력을 잃어버리거나 또는 출력이 겹쳐서 쓰일 수 있음

이러한 코드 부분은 다수 프로세스가 병행으로 접근할 수 없도록 그 진입점에서 인터럽트를 불능화하고 출구에서 인터럽트를 다시 가능화함

<br>
<br>

### 4. 디스패처
📢 ***디스패처(dispatcher) : CPU 코어의 제어를 CPU 스케줄러가 선택한 프로레스에 주는 모듈이며, 다음과 같은 작업을 포함<br>
✔️  한 프로세스에서 다른 프로세스로 문맥을 교환하는 일<br>
✔️ 사용자 모드로 전환하는 일<br>
✔️ 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동하는 일***<br>

<br>

디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, **가능한 한 최고로 빨리 수행**되어야 함

디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는데까지 소요되는 시간을 ***“디스패치 지연”***

<img width="468" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/b3175adf-2c96-4fc1-bcec-b7efa51c724d">

시스템 차원에서 `Linux` 시스템에서 제공되는 `vmstat` 명령을 사용하면 문맥 교환 횟수를 얻을 수 있음

```bash
vmstat 1 3 // 1-초 지연 단위로 3줄의 출력 제공
```

<br>

문맥교환은 두 가지로 구분 됨

- **자발적 문맥 교환 :** 현재 사용 불가능한 자원을 요청했기 때문에 프로세스가 CPU 제어를 포기한 경우 발생
- **비자발적 문맥 교환 :** 타임 슬라이스가 만료되었거나 우선순위가 더 높은 프로세스에 의해 선점된 경우와 같이 CPU 를 빼앗겼을 때 발생

<br>
<br>

## 💭 스케줄링 기준

서로 다른 CPU 스케줄링 알고리즘들은 다른 특성이 있으며 한 부류의 프로세스들은 다른 부류보다 더 선호할 수 있음

특정 상황에서 어떠한 알고리즘을 선택하려면, 우리는 다양한 알고리즘들의 서로 다른 특성을 반드시 고려해야 함
<br>

CPU 스케줄링 알고리즘을 비교하기 위해 여러 기준이 제시되는데 사용되는 기준은 다음을 포함

<br>

**1️⃣ CPU 이용률(utilization)**

- 가능한 CPU를 최대한 바쁘게 유지하기를 원함
- 개념상으로는 CPU 이용률은 `0~100%` 까지 이름
    - 실제 시스템에서는 `40%`(부하가 적은 시스템의 경우) ~ `90%`까지의(부하가 큰 시스템 경우) 범위를 가져야 함

<br>
<br>

**2️⃣ 처리량(throughput)**

- CPU가 프로세스를 수행하느라고 바쁘다면, 작업이 진행되고 있는 것
- 작업량 측정의 한 방법은 단위 시간당 완료된 프로세스의 개수로, 이것을 **처리량**이라 함
- 긴 프로세스인 경우에는 이 비율은 몇 초동안 한 프로세스가 될 수 있고, 짧은 트랜잭션인 경우 처리량은 초당 수십 개의 프로세스가 될 수도 있음

<br>
<br>

**3️⃣ 총처리 시간(turnaround time)**

- 프로세스의 제출 시간과 완료 시간의 간격

  **👉🏻 준비 큐에서 대기한 시간 + CPU에서 실행한 시간 + 입출력 시간**

<br>
<br>

4️⃣ **대기 시간(waiting time)**

- **대기 시간**은 **준비 큐에서 대기하면서 보낸 시간의 합**
    - CPU 스케줄링 알고리즘은 프로세스가 실행하거나 I/O을 하는 시간의 양에 영향을 미치지는 않음

<br>
<br>

5️⃣ **응답 시간(response time)**

- 대화식 시스템(interactive system)에서, 총처리 시간은 최선의 기준이 아닐 수도 있음
- 프로세스가 어떤 출력을 매우 일찍 생성하고, 앞의 결과가 사용자에게 출력되는 사이에 새로운 결과를 얻으려고 연산을 계속하는 경우가 종종 있음
- 따라서 또 다른 기준은 **하나의 요구를 제출한 후 첫 번째 응답이 나올 때까지의 시간**
    - 응답 시간이라고 하는 이 기준은 응답이 시작되는 데까지 걸리는 시간이지, 그 응답을 출력하는 데 걸리는 시간 ❌

<br>
<br>

> ***CPU 이용률과 처리량을 최대화하고 총처리 시간, 대기 시간, 응답 시간을 최소화하는 것이 바람직함**
대부분 경우, 평균 측정 시간을 최적화하려고 하지만, 어떤 경우엔 평균보다는 최솟값 또는 최댓값을 최적화하는 것이 바람직할 수도 있음*
>

<br>
<br>

## 💭 스케줄링 알고리즘

CPU 스케줄링은 준비 큐에 있는 어느 프로세스에 CPU 코어를 할당할 것인지를 결정하는 문제를 다룸

대부분 최신 CPU 아키텍처에는 여러 개의 처리 코어가 있지만 이런 스케줄링 알고리즘을 처리 코어가 하나뿐이라고 가정하고 설명함

***즉, 한 개의 처리 코어를 가진 CPU가 한 개인 시스템이므로 한 번에 하나의 프로세스만 실행할 수 있음***

<br>
<br>

### 1. 선입 선처리 스케줄링(FCFS)
📢 ***FCFS: CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받음***

<br>

<img width="780" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/0acc0ab5-9929-4be4-85c4-20a620f5cb9a">

👉🏻 ***선입 선처리 정책하에서 평균대기 시간은 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 크게 변할 경우에는 평균대기 시간도 상당히 변할 수 있음***

<br>

✅ FCFS 스케줄링은 **비선점형**

<br>
<br>

➕ **호위 효과(convoy effect) :** 모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다리는 것

- 하나의 CPU 중심 프로세스와 많은 수의 I/O 중심 프로세스를 갖는다고 가정하자
    - CPU 중심 프로세스가 CPU를 할당받아 점유하게 되는데 그동안 다른 모든 프로세스들은 I/O를 끝내고 준비 큐로 이동해 CPU를 기다림
    - 프로세스들이 준비 큐에서 기다리는 동안, I/O 장치들은 쉬고 있고, CPU 중심 프로세스가 자신의 CPU 버스트를 끝내고 I/O 장치로 이동
    - 모든 I/O 중심의 프로세스들은 매우 짧은 CPU 버스트를 갖고 있기 때문에, CPU 작업을 신속하게 끝내고 다시 I/O 큐로 이동
    - 이 시점에서 CPU가 쉬게 되는데 그러면 CPU 중심 프로세스는 다시 준비 큐로 이동해 CPU를 할당받음
    - CPU 중심 프로세스가 끝날 때까지 모든 I/O 프로세스들은 다시 준비 큐에서 기다리게 됨

*👉🏻 이 효과는 **짧은 프로세스들이 먼저 처리되도록 허용될 때보다 CPU와 장치 이용률이 저하되는 결과를 초래**함*

<br>
<br>

**❗️FCFS 알고리즘은 특히 대화형 시스템에서 문제가 발생**

대화형 시스템에서는 각 프로세스가 규칙적인 간격으로 CPU 몫을 얻는 것이 매우 중요하기 때문

<br>
<br>

### 2. 최단 작업 우선 스케줄링(SJF)
📢 ***SJF : CPU가 이용 가능해지면, 다음 CPU 버스트가 가장 짧은 프로세스에게 할당함 <br>
✔️ 동일한 CPU 버스트를 가지면 선입 선출 스케줄링을 적용함 <br>
✔️ 프로세스의 전체 길이가 아닌 다음 CPU 버스트 길이에 의해 스케줄링됨***

<br>

<img width="782" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/f070e7d6-481e-4df9-8cdf-3068641e8eac">

***👉🏻 주어진 프로세스 집합에 대해 최소의 평균대기 시간을 가진다는 점에서 최적이라고 볼 수 있음***

*👉🏻 짧은 프로세스의 대기 시간은 줄이고 긴 프로세스의 대기 시간은 증가하게 됨*

<br>
<br>

✅ SJF 알고리즘은 **선점형이거나 또는 비선점형**일 수 있음

- **비선점형**
    - 실행중인 프로세스가 CPU 버스트를 완료할 때까지는 선점하지 않음
- **선점형**
    - 새로운 프로세스가 현재 실행되고 있는 프로세스의 남은 시간보다 짧은 버스트를 가지면 현재 실행중인 프로세스를 선점
    - 선점형 SJF 알고리즘은 때때로 최소 잔여 시간 우선 스케줄링(SRTF)이라 부름
      <img width="693" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/55b0bd11-6eaa-4f8e-9319-97d86ebfcaa6">

<br>
<br>

**❗️SJF 알고리즘이 최적이긴 하나, 다음 CPU 버스트 길이를 알 방법이 없기 때문에 CPU 스케줄링 수준에서는 구현할 수 없음**

한 가지 접근 방식은 SJF 스케줄링과 근사한 방법을 사용하는 것인데, 다음 CPU 버스트의 길이를 알 수 없으나, 그 값을 예측할 수는 있을 것

<img width="627" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/711d732a-1f1a-4c9b-9b31-c4fbd1f8bcaa">

<br>
<br>

### 3. 라운드 로빈 스케줄링(RR)
📢 ***RR : 선입 선처리 스케줄링과 유사하지만 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가됨 <br>
✔️ 시간 할당량(time quan-tum) 또는 타임슬라이스(time slice) 라 하는 작은 단위의 시간을 정의(10~100밀리초)***

<br>

<img width="773" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/a7a217ed-4a74-4a3c-b97b-f785aba36054">

👉🏻 ***CPU 스케줄러는 준비 큐를 돌아가면서 한 번에 한 프로세스에 한 번의 시간 할당량만큼 CPU를 할당***

<br>
<br>

✅ RR 스케줄링은 무조건 **선점형**

<br>
<br>

🤔 **RR 스케줄링 구현**

준비 큐가 선입선출 큐로 동작하게 만들음

새로운 프로세스들(새로운 프로세스 or 다시 들어온 프로세스)은 준비 큐의 꼬리에 추가됨

CPU 스케줄러는 준비 큐에서 첫 번째 프로세스(처음 들어온 프로세스 또는 실행 중이던 프로세스의 다음 프로세스)를 선택해 한 번의 시간 할당량 이후 인터럽트를 걸도록 타이머를 설정한 후, 프로세스를 디스패치 함

두 가지 중 하나 발생

***1) 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 작은 경우***

- 프로세스 자신이 CPU를 자발적으로 방출하고 스케줄러는 그 후 준비 큐에 있는 다음 프로세스로 진행

<br>

***2) 실행 중인 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 긴 경우***

- 타이머가 끝나면서 인터럽트 발생

- 문맥 교환이 일어나고 실행하던 프로세스는 준비 큐의 꼬리에 추가되고, CPU 스케줄러는 준비 큐의 다음 프로세스를 선택

<br>

**❗️시간 할당량의 크기에 매우 많은 영향을 받음**

극단적인 경우, 시간 할당량이 매우 크게 되면, RR 정책은 선입 선처리 정책과 같음

이와 반대로 시간 할당량이 매우 적다면, RR 정책은 매우 많은 문맥 교환을 야기

반환 시간은 시간 할당량의 크기에 좌우됨

<img width="461" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/fe00e947-473a-470f-ba55-95a3ada7763c">
<img width="346" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/ed660771-1bac-459d-a4a3-b703e8cb092c">

**👉🏻 작다고 무조건 장땡은 ❌**

<br>
<br>

> ***시간 할당량이 문맥 교환에 비해 커야 하지만 너무 커서는 안 됨**
앞서 지적한 것처럼 **시간 할당량이 너무 크다면 RR 스케줄링은 선입 선처리 정책으로 퇴보**하게 됨
CPU 버스트의 80%는 시간 할당량보다 짧아야 하는 것을 권장*
>

<br>
<br>

### 4. 우선순위 스케줄링

📢 ***우선순위 스케줄링 : CPU는 가장 높은 우선순위를 가진 프로세스에 할당 <br>
✔️ SJF 알고리즘은 일반적인 우선순위 스케줄링 알고리즘의 특별한 경우 <br>
✔️ 우선순위가 같은 프로세스들은 선입 선처리(FCFS) 순서로 스케줄***

<br>

<img width="766" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/7cdbb578-d38c-4ec8-a134-f0d242170c5c">
👉🏻 만약 P3이 P1과 같은 우선순위 3이 된다면, 버스트 시간은 고려하지 않고 먼저 도착한 걸 처리하게 됨

<br>
<br>

**➕ 우선순위 정의**

우선순위는 **내부적 또는 외부적**으로 정의될 수 있음

- **내부적 정의된 우선순위**
    - 프로세스의 우선순위를 계산하기 위해 어떤 측정 가능한 양들

      ex) 시간 제한, 메모리 요구, 열린 파일의 수, 평균 I/O 버스트의 평균 CPU 버스트에 대한 비율 등

<br>

- **외부적 정의된 우선순위**
    - 프로세스의 중요성, 컴퓨터 사용을 위해 지불되는 비용의 유형과 양, 그 작업을 후원하는 부서 그리고 정치적 요인등과 같은 운영체제 외부적 결정

<br>
<br>

✅ 우선순위 알고리즘은 **선점형이거나 또는 비선점형**일 수 있음

- **비선점형**
    - 단순히 준비 큐의 머리 부분에 새로운 프로세스를 넣음
- **선점형**
    - 새로 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다 높으면 CPU를 선점

<br>
<br>

**❗️무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation) 발생**

실행 준비는 되어 있으나, CPU를 사용하지 못하는 프로세스는 CPU를 기다리면서 봉쇄된 것으로 간주할 수 있음

우선순위 스케줄링 알고리즘을 사용할 경우 낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우 발생

부하가 과중한 컴퓨터 시스템에서는 높은 우선순위의 프로세스들이 꾸준히 들어와서 낮은 우선순위의 프로세스들이 CPU를 사용하지 못하게 될 수도 있음

<br>
<br>

**🙌🏻 해결방안 : 에이징(aging) & RR과 우선순위 스케줄링 결합**

**1️⃣ 에이징(aginig)**

시스템에서 오래 대기하는 프로세스들의 우선순위를 점진적으로 증가시킴

예를 들어, 우선순위가 127(낮음)에서 0(높음)까지 범위라면, 매 15분마다 대기 중인 프로세스의 우선순위를 1씩 증가시킬 수 있음

<br>
<br>

**2️⃣ RR과 우선순위 스케줄링 결합**

시스템이 우선순위가 높은 프로세스를 실행하고 우선순위가 같은 프로세스들은 RR 스케줄링을 사용해 스케줄링 하는 방식

<img width="781" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3d37ec78-9112-474a-a4f2-c54b5fcaef88">

<br>
<br>

### 5. 다단계 큐 스케줄링

📢 ***다단계 큐 스케줄링 : 우선순위마다의 별도의 준비 큐를 형성해 스케줄링 하는 방법 <br>
✔️ 프로세스들은 프로세스의 특성에 따라 우선순위가 부여되어 한 개의 큐에 영구적으로 할당되는데 각 큐에는 그 성격에 맞는 스케줄링 알고리즘을 별도로 적용할 수 있음(FCFS, RR 등)***

<br>

<img width="772" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6895daff-c1bb-42c6-8f40-8d879efd508d">

***👉🏻 항상 가장 높은 우선순위 큐의 프로세스에게 CPU를 먼저 할당해줌***

<br>
<br>

**🤔 프로세스 유형에 따라 프로세스를 여러개 개별 큐로 분할하기 위해 다단계 큐 스케줄링 알고리즘을 사용할 수 있음**

ex) 흔히 포그라운드(대화형) 프로세스와 백그라운드(배치) 프로세스를 구분

    두 가지 유형의 프로세스는 응답 시간 요구 사항이 다르므로 스케줄링 요구 사항이 다를 수 있음

      또한 포그라운드 프로세스는 백그라운드 프로세스보다 우선순위 를 가질 수 있음

      포그라운드 및 백그라운드 프로세스에 별도의 큐가 사용될 수 있으며 각 큐에는 자체 스케줄링 알고리즘이 있을 수 있음

<br>

추가로 큐와 큐 사이에 스케줄링도 반드시 있어야 하며, 일반적으로 고정 우선순위의 선점형 스케줄링으로 구현됨

ex) 실시간 큐는 대화형 큐보다 절대적으로 높은 우선순위를 지닐 수 있음

<br>
<br>

**➕ 각 큐의 우선순위**

**1) 실시간 프로세스**

**2) 시스템 프로세스**

**3) 대화형 프로세스**

**4) 배치 프로세스**  

<br>

각 큐는 낮은 우선순위의 큐보다 절대적 우선순위를 가짐

ex) 실시간 프로세스, 시스템 프로세스, 대화형 프로세스를 위한 큐들이 모두 비어있지 않으면 배치 큐에 있는 프로세스는 실행될 수 없음

배치 프로세스가 실행되고 있는데, 대화형 프로세스가 준비 큐에 들어가면 배치 프로세스는 선점될 것

<br>

다른 가능성은 큐들 사이에 시간을 나누어 사용

큐 별로 비율을 다르게 해줌

<img width="421" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5868be68-5fff-48ba-8731-646a581a2276">

<br>
<br>

### 6. 다단계 피드백 큐 스케줄링

📢 ***다단계 피드백 큐 스케줄링 : 프로세스가 큐들 사이를 이동하는 것을 허용 <br>
✔️ 다단계 큐 스케줄링 + 동적인 프로세스 우선순위 변화***

<br>
<br>

<img width="811" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/354634a0-1b2f-4ee3-b369-d0a956710c49">

<br>

ex) 예를 들어 그림 5.9처럼 번호가 0~2까지인 세 개의 큐를 가진 다단계 피드백 큐 스케줄러를 생각해보자

이 스케줄러는 처음 큐 0의 모든 프로세스를 실행시킴

큐 0이 비어있을 때만, 큐 1에 있는 프로세스들을 실행시키고 마찬가지로 큐 0과 1이 비어있을때만 큐 2에 있는 프로세스들이 실행됨

큐 1에 도착한 프로세스는 큐 2에 있는 프로세스를 선점하고, 큐 1에 있는 프로세스는 큐 0에 도착한 프로세스에 의해 선점될 것임

<br>
<br>

**🤔 다단계 피드백 큐 스케줄러는 다음 매개변수에 의해 정의**

- 큐의 개수
- 각 큐를 위한 스케줄링 알고리즘
- 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
- 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
- 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법

<br>
<br>

> *다단계 피드백 큐 스케줄러 정의에 의하면 이 스케줄링 알고리즘은 **가장 일반적인 CPU 스케줄링 알고리즘**
이 알고리즘은 설계 중인 특정 시스템에 부합하도록 구성가능 **But,** **가장 좋은 스케줄러로 동작하기 위해서는 모든 매개변수들의 값을 선정하는 특정 방법이 필요함과 동시에 가장 복잡한 알고리즘**이기도 함*
>

<br>
<br>
## 💭 스레드 스케줄링

4장에서 프로세스 모델에 스레드를 도입하면서 **사용자 수준과 커널 수준 스레드**를 구별하였음

대부분 최신 운영체제에서는 스케줄 되는 대상은 **프로세스가 아닌 커널 수준의 스레드**

이 절에서는 사용자 수준과 커널 수준 스레드의 스케줄링에 관한 쟁점을 탐구하고 **Pthreads의 스케줄링** 사례를 제공

<br>
<br>

### 1. 경쟁 범위

사용자 수준과 커널 수준 스레드의 차이 중 하나는 **그들이 어떻게 스케줄 되느냐**

**1️⃣ 프로세스 경쟁 범위(Process Contention Scope; PCS)**

- 다대일 또는 다대다 모델의 시스템
- 동일한 프로세스에 속한 스레드들 사이에서 CPU를 경쟁
- 전형적으로, PCS는 우선순위에 따라 행해짐
    - 우선순위는 프로그래머에 의해 지정
- 사용자 수준 스레드의 우선순위는 프로그래머에 의해 지정되고 스레드 라이브러리에 의해 조정되지 않지만, 몇몇 스레드 라이브러리는 프로그래머가 스레드의 우선순위를 변경하는 것을 허용함
- PCS는 더 높은 우선순위의 스레드를 위해 현재 실행 중인 스레드를 선점한다는 것을 주의
- **But,** 같은 우선순위의 스레드들 사이에는 타임 슬라이스에 대한 보장은 없음

<br>
<br>

**2️⃣ 시스템 경쟁 범위(System Contention Scope; SCS)**

- CPU 상에 어느 커널 스레드를 스케줄링할 것인지를 결정
- CPU에 대한 경쟁은 시스템 상의 모든 스레드 사이에서 일어남
- `Windows` 와 `Linux` 같은 일대일 모델을 사용하는 시스템은 오직 SCS만을 사용해 스케줄

<br>
<br>

### 2. Pthread 스케줄링

스레드를 생성하면서 **PCS** 또는 **SCS**를 지정할 수 있는 POSIX Pthreads API를 강조

Pthreads는 다음과 같은 범위 값을 구분

- PTHREAD SCOPE PROCESS schedules threads using PCS scheduling
- PTHREAD SCOPE SYSTEM schedules threads using SCS scheduling.

<br>
<br>

다대다 모델을 구현하는 시스템에서는 PTHREAD_SCOPE_PROCESS 정책이 사용자 수준 스레드를 가용한 LWP로 스케줄 함

LWP의 개수는 스레드 라이브러리에 의해 유지됨

다대다 시스템에서 이 정책은 각 사용자 수준 스레드를 LWP를 생성하고 바인드하게 될 것이고 결과적으로 일대일 모델을 사용하게 됨

Pthread IPC는 경쟁 범위 정책의 정보를 얻어내고 지정하기 위해 다음과 같은 두 함수를 제공함

- `pthread attr setscope(pthread attr_t *attr, int scope)`
- `pthread attr getscope(pthread attr_t *attr, int *scope)`

<br>

두 함수의 첫 번째 매개변수는 스레드를 위한 속성 집합을 가리키는 포인터를 저장

`pthread_attr_setscope()` 함수의 두 번째 매개변수로는 경쟁 범위가 어떻게 지정되는가를 가리키는 PTHREAD_SCOPE_SYSTEM 또는 PTHREAD_SCOPE_PROCESS 값이 전달됨

`pthread_attr_getscope()` 함수의 경우 이 두 번째 매개변수는 경쟁 범위의 현재 값을 저장할 `int` 값을 가리키는 포인터를 저장함

만일 오류가 발생하면 각 함수들은 `0` 이 아닌 값을 반환

<img width="712" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/fc9c1b05-3f60-4956-b996-72d732924d49">

<br>
<br>

## 💭 다중 처리기 스케줄링

지금까지는 단일 처리기 시스템에서의 CPU 스케줄링에 대해서 알아보았음

한 시스템 내에서 여러 개의 CPU가 사용 가능하다면, 어떤 것들이 변화되고 어떤 문제들이 추가적으로 발생할까 ?

여러 개의 CPU 사용 가능 → 여러 스레드 병렬로 실행 가능 → **부하 공유**

<br>

다중 처리기에서는 **부하 공유(load sharing)** 이 가능해짐

  👉🏻 쉬고 있는 처리기에 할 일을 부여하는 것, 한 처리기는 계속 일하고 나머지는 놀고 있는 상태가 되어서는 안 됨

<br>

**But,** 이에 따라 **스케줄링은 더욱 복잡**해짐
동일한 다중 처리기일지라도, 때로는 스케줄링에 어떠한 제한 사항이 걸려있을 수 있기 때문임

<br>
<br>

### 1. 다중 처리기 스케줄링에 대한 접근 방법

📢 ***일반적으로, 다중 처리기는 여러 개의 물리적 프로세서를 제공하는 시스템을 말함 <br>
✔️ 각 프로세서에는 하나의 단일 코어 CPU가 포함되어 있음***

<br>

최신 컴퓨팅 시스템에서의 다중 처리기는 아래의 아키텍처들을 사용 가능

- 다중 코어 CPU
- 다중 스레드 코어
- NUMA 시스템
- 이기종 다중 처리

<br>
<br>

**1️⃣ 비대칭 다중 처리(asymmetric multiprocessing)**

- 마스터 서버라는 하나의 처리기가 모든 스케줄링 결정, I/O 처리, 다른 시스템의 활동을 취급
- 다른 처리기들은 사용자 코드만을 수행
- 하나의 코어만 시스템 자료구조에 접근해 자료 고유의 필요성을 배제하기 때문에 매우 간단
- **But, 마스터 서버가 전체 시스템 성능을 저하할 수 있는** 병목이 될 수 있음

<br>
<br>

**2️⃣ 대칭 다중 처리(Symmetric Multi Processing; SMP)**

- 다중 처리기를 지원하기 위한 표준 접근 방식
- 각 프로세서는 독자적으로 스케줄링할 수 있음
- 각 프로세서의 스케줄러가 준비 큐를 검사하고 실행할 스레드를 선택해서 스케줄링이 진행됨
- 스케줄링 대상이 되는 스레드를 관리하기 위한 두 가지 전략 제공

  1)  모든 스레드가 공통 준비 큐에 있을 수 있음

    <img width="494" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/e82a725d-146f-4ac7-9a12-09e6e001d8aa">
    
  👉🏻 공유 준비 큐에서 **경쟁 조건**이 생길 수 있음 <br>
  👉🏻 **두 개의 다른 프로세스가 동일한 스레드를 스케줄 하지 않도록, 큐에서 스레드가 없어지지 않도록 보장해야 함**

<br>

          2)  각 프로세서는 자신만의 스레드 큐를 가질 수 있음
    
      <img width="463" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/38ac7f50-be82-4a7a-ab68-3dd29e9e8734">

         👉🏻  각 프로세서가 자신만의 실행 큐에서 스레드를 스케줄 하도록 허용

         👉🏻 자신만의 프로세스 실행 큐가 있어서 캐시 메모리를 보다 효율적으로 사용 가능

         👉🏻 큐마다 부하의 양이 다를 수 있음

         👉🏻  균형 알고리즘을 통해 프로세서 간 부하를 균등하게 만들 수 있음

<br>
<br>

> ***여러 개의 처리기가 공동 자료구조를 접근하고 갱신하려고 한다면, 스케줄러는 신중하게 프로그램되어야 함***
>

<br>
<br>

### 2. 다중 코어 프로세서

📢 ***다중 코어 프로세서 : 동일한 물리적인 칩 안에 여러 개의 처리 코어를 장착 <br>
✔️ 각 코어는 구조적인 상태를 유지하고 있어, 운영체제 입장에서는 개별적인 논리적 CPU로 보임***

<br>

다중 코어 프로세서를 사용하는 SMP 시스템은 속도가 빠르고 적은 전력을 소모함

각 CPU가 자신의 물리 칩을 갖는 시스템과 비교해 상대적으로 빠름

이러한 다중 코어 프로세서는 **스케줄링 문제를 복잡하게 만들음**

<br>

**메모리 스톨(memory stall)**

<img width="716" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/1052eeb2-05c2-4f75-ac55-597cef3fc7a4">
프로세서가 메모리에 접근할 때 데이터가 가용할때 까지를 대기하는 것

다중 코어 프로세서는 메모리 스톨에 많은 시간을 허비할 수 있음

캐시 미스(캐시 메모리에 접근하려는 데이터가 없는 경우) 등의 여러 원인 때문에 발생함

<br>

위 그림은 메모리 스톨을 묘사하는데, 이 시나리오에서는 프로세서는 메모리의 데이터를 사용할 수 있을 때까지 기다리느라 최대 50%의 시간을 허비할 수 있음

<br>
<br>

**🙌🏻 메모리 스톨 해결 방법 : 칩 다중 스레딩**

최근 많은 하드웨어 설계는 다중 스레드 처리 코어를 구현하였음

    👉🏻 하나의 코어에 2개 이상 하드웨어 스레드가 할당됨

<br>

메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면, 코어가 다른 스레드로 전환할 수 있음
<img width="722" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5342d3d7-7485-400e-ad53-427a1f7e194f">

<br>
<br>

**칩 다중 스레딩(Chip Multi Threading, CMT)**

<img width="440" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/02e63877-d65d-4f1a-a23a-63d8c9bc205b">

운영체제 관점에서 각 하드웨어 스레드는 소프트웨어 스레드를 실행할 수 있는 논리적 CPU로 보임

각 하드웨어 스레드는 명령어 포인터 및 레지스터 집합과 같은 구조적 상태를 유지

위 그림에서, 프로세서에는 4개의 컴퓨팅 코어가 있고 각 코어에는 2개의 하드웨어 스레드가 존재함

운영체제의 관점에서 볼 때는 **총 8개의 논리적 CPU가 존재**

`Intel` 프로세서는 **“하이퍼 스레딩(동시 다중 스레딩 또는 SMT)”** 라는 용어를 사용

    👉🏻 **단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것을 설명**하기 위함

<br>
<br>

일반적으로 처리기를 다중 스레드화 하는 데에는 2가지 방법이 존재함

**1️⃣ 거친 다중 스레딩**

- 스레드가 메모리 스톨과 같은 **긴 지연시간을 가진 이벤트가 발생할 때까지 한 코어에서 수행됨**

  👉🏻 긴 지연시간을 가진 이벤트 : 메모리 스톨 등

- 긴 지연시간을 가진 이벤트에 의한 지연에 의해 코어는 다른 스레드를 실행하게 됨
- 프로세서 코어에서 다른 스레드가 수행되기 전에 명령어 파이프라인이 완전히 정리되어야 함

  👉🏻 **스레드 간 교환에는 비용이 많이 들음**

- 새로운 스레드가 실행을 시작하면 자신의 명령어들로 파이프라인을 채움

<br>
<br>

**2️⃣ 세밀한 다중 스레딩**

- 명령어 주기의 경계에서 같이 좀 더 세밀한 정밀도를 가진 시점에서 스레드 교환이 발생함
- 세밀한 시스템의 구조적 설계는 **스레드 교환을 위한 회로를 포함**

  **👉🏻 스레드 간 교환 비용이 적음**

<br>
<br>

다중 스레드 다중 코어 프로세서는 그림과 같이 현실적으로 두 개의 다른 스케줄링 단계가 필요함

<img width="441" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/2c0510b6-04d2-40dd-9812-7d814a8e90c9">

물리적 코어의 자원은 하드웨어 스레드 간에 공유되어야 함

👉🏻 처리 코어는 한 번에 하나의 하드웨어 스레드만 실행할 수 있음

👉🏻 결과적으로 다중 스레드 다중 코어 프로세서는 두 개의 다른 스케줄링 단계가 필요함

<br>

**1단계 : 운영체제가 각 하드웨어 스레드에서 실행할 소프트웨어 스레드를 선택하는 스케줄링 결정**

👉🏻 이 스케줄링 수준 대해서 운영체제는 알고리즘을 포함해 임의의 스케줄링 알고리즘을 선택할 수 있음

<br>

**2단계 : 각 코어가 실행할 하드웨어 스레드를 결정하는 방법을 명시함**

이 상황에서 채택할 수 있는 몇 가지 전략이 존재함

<br>

**1️⃣ RR을 사용해 처리 코어에 하드웨어 스레드를 스케줄 ✅**

- 가장 간단한 방법
- `UltraSPARC` `T3` 에 의해 채택된 접근 방법

<br>

2️⃣ **각 하드웨어 스레드에는 0~7까지의 동적 긴급도 배정(0: 가장 낮음 / 7: 가장 높음)**

- 코어당 2개의 하드웨어 관리 스레드를 가진 이중 코어 프로세서인 `Intel Itanium` 에서 사용
- 스레드 교환을 촉발할 수 있는 5가지 이벤트를 식별
    - 이벤트 발생 시 : 스레드 - 교환 회로가 두 스레드의 긴급도를 비교해 높은 긴급도를 가진 스레드를 채택해 처리 코어에서 실행

<br>
<br>

**❗️1단계와 2단계가 상호배타적이지 않아도 됨(동시에 발생 OK)**

운영체제 스케줄러가 프로세서 자원 공유를 인식하면 보다 효과적인 스케줄링 결정을 내릴 수 있음

<br>

CPU에 2개의 처리 코어가 있고, 코어에 2개의 하드웨어 스레드가 있다고 가정하자

이 시스템에서 두 개의 소프트웨어 스레드가 실행 중이면, 동일한 코어 또는 서로 다른 코어에서 실행될 수 있음

👉🏻 둘 다 동일한 코어에서 실행되도록 스케줄 된 경우엔 프로세서 자원을 공유해야 하기 때문에, 서로 다른 코어에서 스케줄 될때보다 느리게 진행될 수 있음

<br>

운영체제가 프로세서 자원 공유 수준을 알고 있다면 자원을 공유하지 않는 논리 프로세서에 소프트웨어 스레드를 스케줄 할 수 있음

<br>
<br>

### 3. 부하 균등화

📢 ***부하 균등화(Load Balancing) : SMP 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도하는 것 <br>
✔️ 각 처리기가 실행할 스레드를 위한 자신만의 준비 큐를 갖고 있는 시스템에서만 필요한 기능 <br>
✔️ 공통의 실행 큐만 있는 시스템에서 한 처리기가 쉬게 되면, 바로 공통 큐에서 새로운 프로세스를 선택하기 때문에 부하 균등화는 필요하지 않음***

<br>

SMP 시스템에서 처리기가 여러 개인 것을 최대한 활용하기 위해선 **부하를 균등하게 배분하는 것이 매우 중요**

부하 균등화를 위해서는 2가지 일반적 접근법 존재

**1️⃣ push 이주 방식**

- 특정 태스크가 주기적으로 각 처리기의 부하를 검사
- 불균형 상태로 밝혀진다면 과부하인 처리기에서 쉬고 있거나 한가한 처리기로 스레드를 이동

  👉🏻 부하를 분배

<br>
<br>

**2️⃣ pull 이주 방식**

- 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull
- push / pull은 서로 상호 배타적일 필요는 없음 👉🏻 실제로 부하 균등화 시스템에서 병렬적으로 구현

  ex) Linux CFS 스케줄러, FreeBSD 시스템에서 가용한 ULE 스케줄러는 두 방식을 모두 구현함

<br>
<br>

균등 부하의 개념은 다른 의미를 가질 수 있음

1) 모든 큐에 대략 같은 수의 스레드가 있어야 함

2) 균등이랑 모든 큐에 스레드 우선순위를 균등하게 분배해야 함

3) 특정 상황에서는 이런 전략 중 어떤 것도 충분하지 않을 수 있음

👉🏻 이런 전략들은 스케줄링 알고리즘의 목표와 상충할 수 있음

<br>
<br>

### 4. 처리기 선호도

스레드가 특정 처리기에서 실행 중일 때 캐시 메모리에 어떤 일이 벌어지는가 고려해 보자

👉🏻 스레드에 의해 가장 최근에 접근된 데이터가 그 처리기의 캐시를 채우게 됨

👉🏻 스레드에 의한 잇따른 메모리 접근은 캐시 메모리에서 만족함(warm cache)

<br>
<br>

**🤔 스레드가 다른 처리기로 이주한다면 ?**

첫 번째 프로세서의 캐시 메모리 내용은 무효화 및 두 번째 프로세서의 캐시는 다시 채워져야 함

👉🏻 캐시 무효화 및 다시 채우는 비용은 많이 들음

👉🏻 이주 대신 같은 프로세서에 계속 실행시키면서 warm cache를 이용하려고 함 : ***“프로세서 선호도”***

- 다른 프로세서로 이동시키지 않고 같은 프로세서에 실행시키는 것이 훨씬 이득
- SMP를 지원하는 대부분 운영체제에서 사용하는 방법
- 프로세스는 현재 실행 중인 프로세서에 대한 선호도를 보임

<br>
<br>

스케줄링 가능한 스레드의 큐를 구성하기 위해 **앞서 설명한 두 가지 전략은 프로세서 선호도에 영향을 미침**

1️⃣ **공통 준비 큐 접근 방식**

- 선택된 스레드는 어느 처리기에선 실행될 수 있음
- 스레드가 새 프로세서에 스케줄 되면 해당 프로세서의 캐시를 다시 채워야 함

<br>
<br>

**2️⃣ 프로세서마다 자신만의 큐를 사용**

- 스레드는 항상 동일한 프로세서에 스케줄 되므로 warm cache의 내용을 활용 가능
- 기본적으로 프로세서 별 준비 큐는 프로세서 선호도를 무료로 제공

<br>
<br>

처리기 선호도는 여러 형태를 띔

**1️⃣ 약한 선호도(soft affinity)**

- 운영체제가 같은 처리기에서 프로세스를 실행시키기 위해 노력하지만, 보장하지는 않음
- 운영체제는 프로세스를 특정 처리기에서 실행시키려고 하지만 처리기 사이를 이주하는 것은 가능

<br>
<br>

**2️⃣ 강한 선호도(hard affinity)**

- 프로세스는 자신이 실행될 처리기 집합을 명시할 수 있는 시스템 콜
- `Linux` 같은 몇몇 시스템이 사용됨

<br>

많은 시스템은 약한 선호도와 강한 선호도를 모두 지원함

예를 들어, `Linux` 는 약한 선호도를 구현하고 있지만 강한 선호도를 지원하는 `sched_setafficnity()` 시스템 콜도 제공하고 있음

- `ched_setafficnity()` : 스레드가 실행할 수 있는 CPU 집합을 지정할 수 있게 함

<br>
<br>

시스템의 메인 메모리 아키텍처는 프로세서 선호도 문제에도 영향을 줄 수 있음

각각 고유한 CPU와 로컬 메모리를 가진 두 개의 물리적 프로세서 칩이 있는 NUMA(Non Uniform Memory Access)를 특징으로 하는 아키텍처를 보여줌

시스템 연결망을 통해 NUMA 시스템의 모든 CPU가 하나의 물리적 주소 공간을 공유할 수 있지만 CPU는 다른 CPU의 로컬 메모리보다 자신의 로컬 메모리에 더 빠르게 액세스 할 수 있음

운영체제의 CPU 스케줄러 및 메모리 배치 알고리즘이 NUMA를 인식하고 협력하는 경우 특정 CPU에 스케줄 된 스레드를 CPU가 있는 위치에 가장 가까운 메모리에 할당해 가능한 가장 빠른 메모리 액세스를 제공할 수 있음

<img width="738" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/308c47b5-60e4-4f29-806f-d48b4c6ef39f">

<br>
<br>

> ***부하 균등화와 메모리 액세스 시간 최소화 사이에는 갈등이 생김**
프로세서 간에 스레드를 이주하면 NUMA 시스템에서 손해가 발생할 수 있는데 이 경우 스레드는 더 긴 메모리 액세스 시간이 필요한 프로세서로 이동될 수 있음
⭐️ 현대 다중 코어 NUMA 시스템에 대한 스케줄링 알고리즘은 상당히 복잡해짐*
>

<br>
<br>

### 5. 이기종 다중 처리

지금까지 설명한 예에서 모든 프로세서는 기능 면에서 동일하므로 어느 스레드건 모든 처리 코어에서 실행될 수 있음

유일한 차이점은 메모리 액세스 시간이 NUMA 시스템뿐만 아니라 부하 균등화 및 프로세서 선호도 정책에 따라 달라질 수 있다는 것

<br>

모바일 시스템은 현재 다중 코어 아키텍처가 채택되어 있지만 일부 시스템은 **이기종 다중 처리(Heterogeneous Multiprocessing; HMP)**로 설계

👉🏻 동일한 명령어 집합을 수행

전력 소비를 유휴 수준으로 조정하는 기능을 포함해 클록 속도 및 전력 관리 측면에서 차이가 나는 코어를 사용하여 설계된 것

<br>

시스템 및 사용자 태스크는 모든 코어에서 실행될 수 있음 👉🏻 **비대칭 다중 처리 형태는 아님**

HMP의 목적은 작업의 특정 요구에 따라 특정 코어에 작업을 할당하여 전력 소비를 더 잘 관리하는 것

<br>
<br>

이를 지원하는 ARM 프로세서의 경우 이 유형의 아키텍처를 **big.LITTLE**이라고 부름

**고성능 big 코어 + 에너지 효율적인 LITTLE 코어**

👉🏻 big 코어 : 많은 에너지를 소비하므로, 짧은 시간 동안만 사용해야 함

👉🏻 little 코어 : 더 적은 에너지를 사용하므로 더 오랫동안 사용할 수 이씀

<br>

`장점`

- 긴 시간 동안 실행해야 할 작업을 little 코어에 할당해 배터리 충전을 보존하는데 도움을 줌
    - 백그라운드 작업과 같은 것들이 긴 시간 동안 실행해야 할 작업
- 대화형 응용 프로그램을 big 코어에 할당
    - 대화형 응용 프로그램 : 많은 처리 능력이 필요하지만, 짧은 기간 동안 실행
- 모바일 장치가 절전 모드인 경우
    - big 코어를 비활성화하고, little 코어에만 의존

<br>

`Windows 10` 은 스케줄링 정책을 선택할 수 있게 하여 HMP 스케줄링을 지원함