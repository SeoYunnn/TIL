# Chapter 05 CPU 스케줄링

## 💭 CPU 스케줄링이란 ?
📢 ***CPU 스케줄링 : 프로세스가 작업을 수행할 때, 언제 어떤 프로세스에 CPU를 할당할 지를 결정하는 작업
<br> ✔️ 운영체제가 CPU를 효율적으로 활용하기 위한 방법
<br> ✔️ 여러 프로세스들 중 어떤 프로세스를 먼저 실행할 지, 얼마나 오랫동안 실행할 지를 결정하는 일련의 과정***

<br>
<br>

### 1. CPU-I/O 버스트 사이클

CPU 스케줄링의 성공은 프로세스들의 다음과 같은 관찰된 성질에 의해 구분됨

- **CPU 실행**
- **I/O 대기 사이클**

프로세스들은 이들 두 상태 사이를 교대로 이동함

프로세스 실행은 CPU 버스트로 시작되고, 그 후 I/O 버스트가 발생하고, 잇따라 또 다른 CPU 버스트가 발생하고 또 다른 I/O 버스트로 진행

마지막 CPU 버스트는 또 다른 I/O 버스트가 뒤따르는 대신, 실행을 종료하기 위해 시스템 요청과 함께 끝남

<img width="586" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/f88138b9-8094-4842-be72-f37a138e3cb8">

<img width="628" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/7d8802e1-a68d-436b-ab8a-c464309d6fc0">

CPU 버스트들의 지속 시간을 측정한 결과 이들은 프로세스나 컴퓨터마다 변화가 크지만, 그림처럼 유사한 빈도수 곡선을 갖는 경향이 있음

짧은 CPU 버스트가 많이 있고 긴 CPU 버스트는 적음

I/O 중심의 프로그램은 전형적으로 짧은 CPU 버스트를 많이 가질 것이라고 예상됨

CPU 지향 프로그램은 다수의 긴 CPU 버스트를 가질 수 있는데 이러한 분포는 CPU 스케줄링 알고리즘을 구현할 때 매우 중요할 수 있는 사항

<br>
<br>

### 2. CPU 스케줄러

CPU가 유휴 상태가 될 때마다, 운영체제는 준비 큐에 있는 프로세스 중 하나를 선택해 실행

선택 절차는 CPU 스케줄러에 의해 수행되는데, 스케줄러는 실행 준비가 되어 있는 메모리 내의 프로세스 중에서 선택해 이들 중 하나에게 CPU를 할당

<br>

**준비 큐**는 **반드시 선입선출(FIFO) 방식의 큐가 아니어도 되는 것에 유의**해야 함

여러 가지 스케줄링 알고리즘들을 고려할 때 알게 되겠지만, **준비 큐**는 **선입선출 큐, 우선순위 큐, 트리 또는 단순히 순서가 없는 연결리스트**로 구현할 수 있음

**But,** 개념적으로는 준비 큐에 있는 모든 프로세스가 CPU에서 실행할 차례를 기다리며 줄을 서 있는 것으로 생각할 수 있음

큐 안에 있는 레코드는 일반적으로 프로세스의 PCB로 구성되어 있음

<br>
<br>

### 3. 선점 및 비선점 스케줄링

CPU 스케줄링 결정은 네 가지 상황에서 발생할 수 있음

***1) 한 프로세스가 실행 상태에서 대기 상태로 전환***

- ex) I/O 요청이나 자식 프로세스가 종료되기를 기다리기 위해 `wait()` 를 호출할 때

<br>

***2) 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때***

- ex) 인터럽트가 발생

<br>

***3) 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때***

- ex) I/O 종료

<br>

***4) 프로세스가 종료할 때***

상황 1, 4의 경우에는 스케줄링 면에서는 선택의 여지가 없음

실행을 위해 새로운 프로세스(준비 큐에 하나라도 존재할 경우)가 반드시 선택되어야 함

반면, 상황 2, 3은 선택의 여지가 있음

<br>

상황 1과 4에서만 스케줄링이 발생할 경우에는 ***“비선점”*** 또는 ***“협조적”*** 이라 함

그렇지 않은 상황이라면 ***“선점”*** 이라 함

비선점 스케줄링에서는, CPU가 한 프로세스에 할당되면 프로세스가 종료하든지 또는 대기 상태로 전환해 CPU를 방출할 때까지 점유함

- `Windows`, `macOS`, `Linux` 및 `UNIX` 를 포함한 거의 모든 최신 운영체제들은 선점 스케줄링 알고리즘을 사용함

<br>

**But, 선점 스케줄링**은 데이터가 다수의 프로세스에 의해 공유될 때 **경쟁 조건을 초래할 수 있음**

또한 **운영체제 커널 설계에 영향**을 미침

시스템 콜을 처리할 동안, 커널은 한 프로세스를 위한 활동(I/O 큐와 같은)으로 바쁠 수 있음

이런 활동은 중요한 커널자료 변경을 포함할 수 있는데 변경 도중에 해당 프로세스가 선점되고 커널이 동일한 구조를 읽거나 변경할 필요가 있으면 지속적으로 혼란이 야기될 수 있음

<br>

운영체제 커널은 선점 또는 비선점 방식으로 설계될 수 있음

비선점형 커널은 문맥 교환을 하기 전 시스템 콜이 완료되거나 입출력 완료를 기다리며 프로세스가 봉쇄되기를 기다림

커널 자료구조가 비일관적인 상태에 있을 때 커널이 해당 프로세스를 선점하지 않기 때문에, 이런 방법은 커널 구조를 단순하게 만들음

😡 이러한 커널 실행 모델은 **주어진 시간 안에 태스크의 실행이 완료되어야 하는 실시간 컴퓨팅을 지원하기에는 좋은 모델이 아님**

<br>

선점형 커널에는 공유 커널 데이터 구조에 액세스 할 때 경쟁 조건을 방지하기 위해 mutex 락과 같은 기법 필요

대부분 최신 운영체제는 이제 커널 모드에서 실행될 때 완전히 선점될 수 있음

<br>

인터럽트는 어느 시점에서건 일어날 수 있고, 커널에 의해서 항상 무시될 수는 없기 때문에 인터럽트에 의해서 영향을 받는 코드 부분은 반드시 동시 사용으로부터 보호되어야 함

운영체제는 거의 항상 인터럽트를 받아들일 필요가 있는데, 그렇지 않으면 입력을 잃어버리거나 또는 출력이 겹쳐서 쓰일 수 있음

이러한 코드 부분은 다수 프로세스가 병행으로 접근할 수 없도록 그 진입점에서 인터럽트를 불능화하고 출구에서 인터럽트를 다시 가능화함

<br>
<br>

### 4. 디스패처
📢 ***디스패처(dispatcher) : CPU 코어의 제어를 CPU 스케줄러가 선택한 프로레스에 주는 모듈이며, 다음과 같은 작업을 포함<br>
✔️  한 프로세스에서 다른 프로세스로 문맥을 교환하는 일<br>
✔️ 사용자 모드로 전환하는 일<br>
✔️ 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동하는 일***<br>

<br>

디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, **가능한 한 최고로 빨리 수행**되어야 함

디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는데까지 소요되는 시간을 ***“디스패치 지연”***

<img width="468" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/b3175adf-2c96-4fc1-bcec-b7efa51c724d">

시스템 차원에서 `Linux` 시스템에서 제공되는 `vmstat` 명령을 사용하면 문맥 교환 횟수를 얻을 수 있음

```bash
vmstat 1 3 // 1-초 지연 단위로 3줄의 출력 제공
```

<br>

문맥교환은 두 가지로 구분 됨

- **자발적 문맥 교환 :** 현재 사용 불가능한 자원을 요청했기 때문에 프로세스가 CPU 제어를 포기한 경우 발생
- **비자발적 문맥 교환 :** 타임 슬라이스가 만료되었거나 우선순위가 더 높은 프로세스에 의해 선점된 경우와 같이 CPU 를 빼앗겼을 때 발생

<br>
<br>

## 💭 스케줄링 기준

서로 다른 CPU 스케줄링 알고리즘들은 다른 특성이 있으며 한 부류의 프로세스들은 다른 부류보다 더 선호할 수 있음

특정 상황에서 어떠한 알고리즘을 선택하려면, 우리는 다양한 알고리즘들의 서로 다른 특성을 반드시 고려해야 함
<br>

CPU 스케줄링 알고리즘을 비교하기 위해 여러 기준이 제시되는데 사용되는 기준은 다음을 포함

<br>

**1️⃣ CPU 이용률(utilization)**

- 가능한 CPU를 최대한 바쁘게 유지하기를 원함
- 개념상으로는 CPU 이용률은 `0~100%` 까지 이름
    - 실제 시스템에서는 `40%`(부하가 적은 시스템의 경우) ~ `90%`까지의(부하가 큰 시스템 경우) 범위를 가져야 함

<br>
<br>

**2️⃣ 처리량(throughput)**

- CPU가 프로세스를 수행하느라고 바쁘다면, 작업이 진행되고 있는 것
- 작업량 측정의 한 방법은 단위 시간당 완료된 프로세스의 개수로, 이것을 **처리량**이라 함
- 긴 프로세스인 경우에는 이 비율은 몇 초동안 한 프로세스가 될 수 있고, 짧은 트랜잭션인 경우 처리량은 초당 수십 개의 프로세스가 될 수도 있음

<br>
<br>

**3️⃣ 총처리 시간(turnaround time)**

- 프로세스의 제출 시간과 완료 시간의 간격

  **👉🏻 준비 큐에서 대기한 시간 + CPU에서 실행한 시간 + 입출력 시간**

<br>
<br>

4️⃣ **대기 시간(waiting time)**

- **대기 시간**은 **준비 큐에서 대기하면서 보낸 시간의 합**
    - CPU 스케줄링 알고리즘은 프로세스가 실행하거나 I/O을 하는 시간의 양에 영향을 미치지는 않음

<br>
<br>

5️⃣ **응답 시간(response time)**

- 대화식 시스템(interactive system)에서, 총처리 시간은 최선의 기준이 아닐 수도 있음
- 프로세스가 어떤 출력을 매우 일찍 생성하고, 앞의 결과가 사용자에게 출력되는 사이에 새로운 결과를 얻으려고 연산을 계속하는 경우가 종종 있음
- 따라서 또 다른 기준은 **하나의 요구를 제출한 후 첫 번째 응답이 나올 때까지의 시간**
    - 응답 시간이라고 하는 이 기준은 응답이 시작되는 데까지 걸리는 시간이지, 그 응답을 출력하는 데 걸리는 시간 ❌

<br>
<br>

> ***CPU 이용률과 처리량을 최대화하고 총처리 시간, 대기 시간, 응답 시간을 최소화하는 것이 바람직함**
대부분 경우, 평균 측정 시간을 최적화하려고 하지만, 어떤 경우엔 평균보다는 최솟값 또는 최댓값을 최적화하는 것이 바람직할 수도 있음*
>

<br>
<br>

## 💭 스케줄링 알고리즘

CPU 스케줄링은 준비 큐에 있는 어느 프로세스에 CPU 코어를 할당할 것인지를 결정하는 문제를 다룸

대부분 최신 CPU 아키텍처에는 여러 개의 처리 코어가 있지만 이런 스케줄링 알고리즘을 처리 코어가 하나뿐이라고 가정하고 설명함

***즉, 한 개의 처리 코어를 가진 CPU가 한 개인 시스템이므로 한 번에 하나의 프로세스만 실행할 수 있음***

<br>
<br>

### 1. 선입 선처리 스케줄링(FCFS)
📢 ***FCFS: CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받음***

<br>

<img width="780" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/0acc0ab5-9929-4be4-85c4-20a620f5cb9a">

👉🏻 ***선입 선처리 정책하에서 평균대기 시간은 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 크게 변할 경우에는 평균대기 시간도 상당히 변할 수 있음***

<br>

✅ FCFS 스케줄링은 **비선점형**

<br>
<br>

➕ **호위 효과(convoy effect) :** 모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다리는 것

- 하나의 CPU 중심 프로세스와 많은 수의 I/O 중심 프로세스를 갖는다고 가정하자
    - CPU 중심 프로세스가 CPU를 할당받아 점유하게 되는데 그동안 다른 모든 프로세스들은 I/O를 끝내고 준비 큐로 이동해 CPU를 기다림
    - 프로세스들이 준비 큐에서 기다리는 동안, I/O 장치들은 쉬고 있고, CPU 중심 프로세스가 자신의 CPU 버스트를 끝내고 I/O 장치로 이동
    - 모든 I/O 중심의 프로세스들은 매우 짧은 CPU 버스트를 갖고 있기 때문에, CPU 작업을 신속하게 끝내고 다시 I/O 큐로 이동
    - 이 시점에서 CPU가 쉬게 되는데 그러면 CPU 중심 프로세스는 다시 준비 큐로 이동해 CPU를 할당받음
    - CPU 중심 프로세스가 끝날 때까지 모든 I/O 프로세스들은 다시 준비 큐에서 기다리게 됨

*👉🏻 이 효과는 **짧은 프로세스들이 먼저 처리되도록 허용될 때보다 CPU와 장치 이용률이 저하되는 결과를 초래**함*

<br>
<br>

**❗️FCFS 알고리즘은 특히 대화형 시스템에서 문제가 발생**

대화형 시스템에서는 각 프로세스가 규칙적인 간격으로 CPU 몫을 얻는 것이 매우 중요하기 때문

<br>
<br>

### 2. 최단 작업 우선 스케줄링(SJF)
📢 ***SJF : CPU가 이용 가능해지면, 다음 CPU 버스트가 가장 짧은 프로세스에게 할당함 <br>
✔️ 동일한 CPU 버스트를 가지면 선입 선출 스케줄링을 적용함 <br>
✔️ 프로세스의 전체 길이가 아닌 다음 CPU 버스트 길이에 의해 스케줄링됨***

<br>

<img width="782" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/f070e7d6-481e-4df9-8cdf-3068641e8eac">

***👉🏻 주어진 프로세스 집합에 대해 최소의 평균대기 시간을 가진다는 점에서 최적이라고 볼 수 있음***

*👉🏻 짧은 프로세스의 대기 시간은 줄이고 긴 프로세스의 대기 시간은 증가하게 됨*

<br>
<br>

✅ SJF 알고리즘은 **선점형이거나 또는 비선점형**일 수 있음

- **비선점형**
    - 실행중인 프로세스가 CPU 버스트를 완료할 때까지는 선점하지 않음
- **선점형**
    - 새로운 프로세스가 현재 실행되고 있는 프로세스의 남은 시간보다 짧은 버스트를 가지면 현재 실행중인 프로세스를 선점
    - 선점형 SJF 알고리즘은 때때로 최소 잔여 시간 우선 스케줄링(SRTF)이라 부름
      <img width="693" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/55b0bd11-6eaa-4f8e-9319-97d86ebfcaa6">

<br>
<br>

**❗️SJF 알고리즘이 최적이긴 하나, 다음 CPU 버스트 길이를 알 방법이 없기 때문에 CPU 스케줄링 수준에서는 구현할 수 없음**

한 가지 접근 방식은 SJF 스케줄링과 근사한 방법을 사용하는 것인데, 다음 CPU 버스트의 길이를 알 수 없으나, 그 값을 예측할 수는 있을 것

<img width="627" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/711d732a-1f1a-4c9b-9b31-c4fbd1f8bcaa">

<br>
<br>

### 3. 라운드 로빈 스케줄링(RR)
📢 ***RR : 선입 선처리 스케줄링과 유사하지만 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가됨 <br>
✔️ 시간 할당량(time quan-tum) 또는 타임슬라이스(time slice) 라 하는 작은 단위의 시간을 정의(10~100밀리초)***

<br>

<img width="773" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/a7a217ed-4a74-4a3c-b97b-f785aba36054">

👉🏻 ***CPU 스케줄러는 준비 큐를 돌아가면서 한 번에 한 프로세스에 한 번의 시간 할당량만큼 CPU를 할당***

<br>
<br>

✅ RR 스케줄링은 무조건 **선점형**

<br>
<br>

🤔 **RR 스케줄링 구현**

준비 큐가 선입선출 큐로 동작하게 만들음

새로운 프로세스들(새로운 프로세스 or 다시 들어온 프로세스)은 준비 큐의 꼬리에 추가됨

CPU 스케줄러는 준비 큐에서 첫 번째 프로세스(처음 들어온 프로세스 또는 실행 중이던 프로세스의 다음 프로세스)를 선택해 한 번의 시간 할당량 이후 인터럽트를 걸도록 타이머를 설정한 후, 프로세스를 디스패치 함

두 가지 중 하나 발생

***1) 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 작은 경우***

- 프로세스 자신이 CPU를 자발적으로 방출하고 스케줄러는 그 후 준비 큐에 있는 다음 프로세스로 진행

<br>

***2) 실행 중인 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 긴 경우***

- 타이머가 끝나면서 인터럽트 발생

- 문맥 교환이 일어나고 실행하던 프로세스는 준비 큐의 꼬리에 추가되고, CPU 스케줄러는 준비 큐의 다음 프로세스를 선택

<br>

**❗️시간 할당량의 크기에 매우 많은 영향을 받음**

극단적인 경우, 시간 할당량이 매우 크게 되면, RR 정책은 선입 선처리 정책과 같음

이와 반대로 시간 할당량이 매우 적다면, RR 정책은 매우 많은 문맥 교환을 야기

반환 시간은 시간 할당량의 크기에 좌우됨

<img width="461" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/fe00e947-473a-470f-ba55-95a3ada7763c">
<img width="346" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/ed660771-1bac-459d-a4a3-b703e8cb092c">

**👉🏻 작다고 무조건 장땡은 ❌**

<br>
<br>

> ***시간 할당량이 문맥 교환에 비해 커야 하지만 너무 커서는 안 됨**
앞서 지적한 것처럼 **시간 할당량이 너무 크다면 RR 스케줄링은 선입 선처리 정책으로 퇴보**하게 됨
CPU 버스트의 80%는 시간 할당량보다 짧아야 하는 것을 권장*
>

<br>
<br>

### 4. 우선순위 스케줄링

📢 ***우선순위 스케줄링 : CPU는 가장 높은 우선순위를 가진 프로세스에 할당 <br>
✔️ SJF 알고리즘은 일반적인 우선순위 스케줄링 알고리즘의 특별한 경우 <br>
✔️ 우선순위가 같은 프로세스들은 선입 선처리(FCFS) 순서로 스케줄***

<br>

<img width="766" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/7cdbb578-d38c-4ec8-a134-f0d242170c5c">
👉🏻 만약 P3이 P1과 같은 우선순위 3이 된다면, 버스트 시간은 고려하지 않고 먼저 도착한 걸 처리하게 됨

<br>
<br>

**➕ 우선순위 정의**

우선순위는 **내부적 또는 외부적**으로 정의될 수 있음

- **내부적 정의된 우선순위**
    - 프로세스의 우선순위를 계산하기 위해 어떤 측정 가능한 양들

      ex) 시간 제한, 메모리 요구, 열린 파일의 수, 평균 I/O 버스트의 평균 CPU 버스트에 대한 비율 등

<br>

- **외부적 정의된 우선순위**
    - 프로세스의 중요성, 컴퓨터 사용을 위해 지불되는 비용의 유형과 양, 그 작업을 후원하는 부서 그리고 정치적 요인등과 같은 운영체제 외부적 결정

<br>
<br>

✅ 우선순위 알고리즘은 **선점형이거나 또는 비선점형**일 수 있음

- **비선점형**
    - 단순히 준비 큐의 머리 부분에 새로운 프로세스를 넣음
- **선점형**
    - 새로 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다 높으면 CPU를 선점

<br>
<br>

**❗️무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation) 발생**

실행 준비는 되어 있으나, CPU를 사용하지 못하는 프로세스는 CPU를 기다리면서 봉쇄된 것으로 간주할 수 있음

우선순위 스케줄링 알고리즘을 사용할 경우 낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우 발생

부하가 과중한 컴퓨터 시스템에서는 높은 우선순위의 프로세스들이 꾸준히 들어와서 낮은 우선순위의 프로세스들이 CPU를 사용하지 못하게 될 수도 있음

<br>
<br>

**🙌🏻 해결방안 : 에이징(aging) & RR과 우선순위 스케줄링 결합**

**1️⃣ 에이징(aginig)**

시스템에서 오래 대기하는 프로세스들의 우선순위를 점진적으로 증가시킴

예를 들어, 우선순위가 127(낮음)에서 0(높음)까지 범위라면, 매 15분마다 대기 중인 프로세스의 우선순위를 1씩 증가시킬 수 있음

<br>
<br>

**2️⃣ RR과 우선순위 스케줄링 결합**

시스템이 우선순위가 높은 프로세스를 실행하고 우선순위가 같은 프로세스들은 RR 스케줄링을 사용해 스케줄링 하는 방식

<img width="781" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3d37ec78-9112-474a-a4f2-c54b5fcaef88">

<br>
<br>

### 5. 다단계 큐 스케줄링

📢 ***다단계 큐 스케줄링 : 우선순위마다의 별도의 준비 큐를 형성해 스케줄링 하는 방법 <br>
✔️ 프로세스들은 프로세스의 특성에 따라 우선순위가 부여되어 한 개의 큐에 영구적으로 할당되는데 각 큐에는 그 성격에 맞는 스케줄링 알고리즘을 별도로 적용할 수 있음(FCFS, RR 등)***

<br>

<img width="772" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/6895daff-c1bb-42c6-8f40-8d879efd508d">

***👉🏻 항상 가장 높은 우선순위 큐의 프로세스에게 CPU를 먼저 할당해줌***

<br>
<br>

**🤔 프로세스 유형에 따라 프로세스를 여러개 개별 큐로 분할하기 위해 다단계 큐 스케줄링 알고리즘을 사용할 수 있음**

ex) 흔히 포그라운드(대화형) 프로세스와 백그라운드(배치) 프로세스를 구분

    두 가지 유형의 프로세스는 응답 시간 요구 사항이 다르므로 스케줄링 요구 사항이 다를 수 있음

      또한 포그라운드 프로세스는 백그라운드 프로세스보다 우선순위 를 가질 수 있음

      포그라운드 및 백그라운드 프로세스에 별도의 큐가 사용될 수 있으며 각 큐에는 자체 스케줄링 알고리즘이 있을 수 있음

<br>

추가로 큐와 큐 사이에 스케줄링도 반드시 있어야 하며, 일반적으로 고정 우선순위의 선점형 스케줄링으로 구현됨

ex) 실시간 큐는 대화형 큐보다 절대적으로 높은 우선순위를 지닐 수 있음

<br>
<br>

**➕ 각 큐의 우선순위**

**1) 실시간 프로세스**

**2) 시스템 프로세스**

**3) 대화형 프로세스**

**4) 배치 프로세스**  

<br>

각 큐는 낮은 우선순위의 큐보다 절대적 우선순위를 가짐

ex) 실시간 프로세스, 시스템 프로세스, 대화형 프로세스를 위한 큐들이 모두 비어있지 않으면 배치 큐에 있는 프로세스는 실행될 수 없음

배치 프로세스가 실행되고 있는데, 대화형 프로세스가 준비 큐에 들어가면 배치 프로세스는 선점될 것

<br>

다른 가능성은 큐들 사이에 시간을 나누어 사용

큐 별로 비율을 다르게 해줌

<img width="421" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5868be68-5fff-48ba-8731-646a581a2276">

<br>
<br>

### 6. 다단계 피드백 큐 스케줄링

📢 ***다단계 피드백 큐 스케줄링 : 프로세스가 큐들 사이를 이동하는 것을 허용 <br>
✔️ 다단계 큐 스케줄링 + 동적인 프로세스 우선순위 변화***

<br>
<br>

<img width="811" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/354634a0-1b2f-4ee3-b369-d0a956710c49">

<br>

ex) 예를 들어 그림 5.9처럼 번호가 0~2까지인 세 개의 큐를 가진 다단계 피드백 큐 스케줄러를 생각해보자

이 스케줄러는 처음 큐 0의 모든 프로세스를 실행시킴

큐 0이 비어있을 때만, 큐 1에 있는 프로세스들을 실행시키고 마찬가지로 큐 0과 1이 비어있을때만 큐 2에 있는 프로세스들이 실행됨

큐 1에 도착한 프로세스는 큐 2에 있는 프로세스를 선점하고, 큐 1에 있는 프로세스는 큐 0에 도착한 프로세스에 의해 선점될 것임

<br>
<br>

**🤔 다단계 피드백 큐 스케줄러는 다음 매개변수에 의해 정의**

- 큐의 개수
- 각 큐를 위한 스케줄링 알고리즘
- 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
- 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
- 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법

<br>
<br>

> *다단계 피드백 큐 스케줄러 정의에 의하면 이 스케줄링 알고리즘은 **가장 일반적인 CPU 스케줄링 알고리즘**
이 알고리즘은 설계 중인 특정 시스템에 부합하도록 구성가능 **But,** **가장 좋은 스케줄러로 동작하기 위해서는 모든 매개변수들의 값을 선정하는 특정 방법이 필요함과 동시에 가장 복잡한 알고리즘**이기도 함*
>

<br>
<br>

## 💭 스레드 스케줄링

4장에서 프로세스 모델에 스레드를 도입하면서 **사용자 수준과 커널 수준 스레드**를 구별하였음

대부분 최신 운영체제에서는 스케줄 되는 대상은 **프로세스가 아닌 커널 수준의 스레드**

이 절에서는 사용자 수준과 커널 수준 스레드의 스케줄링에 관한 쟁점을 탐구하고 **Pthreads의 스케줄링** 사례를 제공

<br>
<br>

### 1. 경쟁 범위

사용자 수준과 커널 수준 스레드의 차이 중 하나는 **그들이 어떻게 스케줄 되느냐**

**1️⃣ 프로세스 경쟁 범위(Process Contention Scope; PCS)**

- 다대일 또는 다대다 모델의 시스템
- 동일한 프로세스에 속한 스레드들 사이에서 CPU를 경쟁
- 전형적으로, PCS는 우선순위에 따라 행해짐
    - 우선순위는 프로그래머에 의해 지정
- 사용자 수준 스레드의 우선순위는 프로그래머에 의해 지정되고 스레드 라이브러리에 의해 조정되지 않지만, 몇몇 스레드 라이브러리는 프로그래머가 스레드의 우선순위를 변경하는 것을 허용함
- PCS는 더 높은 우선순위의 스레드를 위해 현재 실행 중인 스레드를 선점한다는 것을 주의
- **But,** 같은 우선순위의 스레드들 사이에는 타임 슬라이스에 대한 보장은 없음

<br>
<br>

**2️⃣ 시스템 경쟁 범위(System Contention Scope; SCS)**

- CPU 상에 어느 커널 스레드를 스케줄링할 것인지를 결정
- CPU에 대한 경쟁은 시스템 상의 모든 스레드 사이에서 일어남
- `Windows` 와 `Linux` 같은 일대일 모델을 사용하는 시스템은 오직 SCS만을 사용해 스케줄

<br>
<br>

### 2. Pthread 스케줄링

스레드를 생성하면서 **PCS** 또는 **SCS**를 지정할 수 있는 POSIX Pthreads API를 강조

Pthreads는 다음과 같은 범위 값을 구분

- PTHREAD SCOPE PROCESS schedules threads using PCS scheduling
- PTHREAD SCOPE SYSTEM schedules threads using SCS scheduling.

<br>
<br>

다대다 모델을 구현하는 시스템에서는 PTHREAD_SCOPE_PROCESS 정책이 사용자 수준 스레드를 가용한 LWP로 스케줄 함

LWP의 개수는 스레드 라이브러리에 의해 유지됨

다대다 시스템에서 이 정책은 각 사용자 수준 스레드를 LWP를 생성하고 바인드하게 될 것이고 결과적으로 일대일 모델을 사용하게 됨

Pthread IPC는 경쟁 범위 정책의 정보를 얻어내고 지정하기 위해 다음과 같은 두 함수를 제공함

- `pthread attr setscope(pthread attr_t *attr, int scope)`
- `pthread attr getscope(pthread attr_t *attr, int *scope)`

<br>

두 함수의 첫 번째 매개변수는 스레드를 위한 속성 집합을 가리키는 포인터를 저장

`pthread_attr_setscope()` 함수의 두 번째 매개변수로는 경쟁 범위가 어떻게 지정되는가를 가리키는 PTHREAD_SCOPE_SYSTEM 또는 PTHREAD_SCOPE_PROCESS 값이 전달됨

`pthread_attr_getscope()` 함수의 경우 이 두 번째 매개변수는 경쟁 범위의 현재 값을 저장할 `int` 값을 가리키는 포인터를 저장함

만일 오류가 발생하면 각 함수들은 `0` 이 아닌 값을 반환

<img width="712" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/fc9c1b05-3f60-4956-b996-72d732924d49">

<br>
<br>

## 💭 다중 처리기 스케줄링

지금까지는 단일 처리기 시스템에서의 CPU 스케줄링에 대해서 알아보았음

한 시스템 내에서 여러 개의 CPU가 사용 가능하다면, 어떤 것들이 변화되고 어떤 문제들이 추가적으로 발생할까 ?

여러 개의 CPU 사용 가능 → 여러 스레드 병렬로 실행 가능 → **부하 공유**

<br>

다중 처리기에서는 **부하 공유(load sharing)** 이 가능해짐

  👉🏻 쉬고 있는 처리기에 할 일을 부여하는 것, 한 처리기는 계속 일하고 나머지는 놀고 있는 상태가 되어서는 안 됨

<br>

**But,** 이에 따라 **스케줄링은 더욱 복잡**해짐
동일한 다중 처리기일지라도, 때로는 스케줄링에 어떠한 제한 사항이 걸려있을 수 있기 때문임

<br>
<br>

### 1. 다중 처리기 스케줄링에 대한 접근 방법

📢 ***일반적으로, 다중 처리기는 여러 개의 물리적 프로세서를 제공하는 시스템을 말함 <br>
✔️ 각 프로세서에는 하나의 단일 코어 CPU가 포함되어 있음***

<br>

최신 컴퓨팅 시스템에서의 다중 처리기는 아래의 아키텍처들을 사용 가능

- 다중 코어 CPU
- 다중 스레드 코어
- NUMA 시스템
- 이기종 다중 처리

<br>
<br>

**1️⃣ 비대칭 다중 처리(asymmetric multiprocessing)**

- 마스터 서버라는 하나의 처리기가 모든 스케줄링 결정, I/O 처리, 다른 시스템의 활동을 취급
- 다른 처리기들은 사용자 코드만을 수행
- 하나의 코어만 시스템 자료구조에 접근해 자료 고유의 필요성을 배제하기 때문에 매우 간단
- **But, 마스터 서버가 전체 시스템 성능을 저하할 수 있는** 병목이 될 수 있음

<br>
<br>

**2️⃣ 대칭 다중 처리(Symmetric Multi Processing; SMP)**

- 다중 처리기를 지원하기 위한 표준 접근 방식
- 각 프로세서는 독자적으로 스케줄링할 수 있음
- 각 프로세서의 스케줄러가 준비 큐를 검사하고 실행할 스레드를 선택해서 스케줄링이 진행됨
- 스케줄링 대상이 되는 스레드를 관리하기 위한 두 가지 전략 제공

  1)  모든 스레드가 공통 준비 큐에 있을 수 있음

    <img width="494" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/e82a725d-146f-4ac7-9a12-09e6e001d8aa">
    
  👉🏻 공유 준비 큐에서 **경쟁 조건**이 생길 수 있음 <br>
  👉🏻 **두 개의 다른 프로세스가 동일한 스레드를 스케줄 하지 않도록, 큐에서 스레드가 없어지지 않도록 보장해야 함**

<br>

          2)  각 프로세서는 자신만의 스레드 큐를 가질 수 있음
    
      <img width="463" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/38ac7f50-be82-4a7a-ab68-3dd29e9e8734">

         👉🏻  각 프로세서가 자신만의 실행 큐에서 스레드를 스케줄 하도록 허용

         👉🏻 자신만의 프로세스 실행 큐가 있어서 캐시 메모리를 보다 효율적으로 사용 가능

         👉🏻 큐마다 부하의 양이 다를 수 있음

         👉🏻  균형 알고리즘을 통해 프로세서 간 부하를 균등하게 만들 수 있음

<br>
<br>

> ***여러 개의 처리기가 공동 자료구조를 접근하고 갱신하려고 한다면, 스케줄러는 신중하게 프로그램되어야 함***
>

<br>
<br>

### 2. 다중 코어 프로세서

📢 ***다중 코어 프로세서 : 동일한 물리적인 칩 안에 여러 개의 처리 코어를 장착 <br>
✔️ 각 코어는 구조적인 상태를 유지하고 있어, 운영체제 입장에서는 개별적인 논리적 CPU로 보임***

<br>

다중 코어 프로세서를 사용하는 SMP 시스템은 속도가 빠르고 적은 전력을 소모함

각 CPU가 자신의 물리 칩을 갖는 시스템과 비교해 상대적으로 빠름

이러한 다중 코어 프로세서는 **스케줄링 문제를 복잡하게 만들음**

<br>

**메모리 스톨(memory stall)**

<img width="716" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/1052eeb2-05c2-4f75-ac55-597cef3fc7a4">
프로세서가 메모리에 접근할 때 데이터가 가용할때 까지를 대기하는 것

다중 코어 프로세서는 메모리 스톨에 많은 시간을 허비할 수 있음

캐시 미스(캐시 메모리에 접근하려는 데이터가 없는 경우) 등의 여러 원인 때문에 발생함

<br>

위 그림은 메모리 스톨을 묘사하는데, 이 시나리오에서는 프로세서는 메모리의 데이터를 사용할 수 있을 때까지 기다리느라 최대 50%의 시간을 허비할 수 있음

<br>
<br>

**🙌🏻 메모리 스톨 해결 방법 : 칩 다중 스레딩**

최근 많은 하드웨어 설계는 다중 스레드 처리 코어를 구현하였음

    👉🏻 하나의 코어에 2개 이상 하드웨어 스레드가 할당됨

<br>

메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면, 코어가 다른 스레드로 전환할 수 있음
<img width="722" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5342d3d7-7485-400e-ad53-427a1f7e194f">

<br>
<br>

**칩 다중 스레딩(Chip Multi Threading, CMT)**

<img width="440" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/02e63877-d65d-4f1a-a23a-63d8c9bc205b">

운영체제 관점에서 각 하드웨어 스레드는 소프트웨어 스레드를 실행할 수 있는 논리적 CPU로 보임

각 하드웨어 스레드는 명령어 포인터 및 레지스터 집합과 같은 구조적 상태를 유지

위 그림에서, 프로세서에는 4개의 컴퓨팅 코어가 있고 각 코어에는 2개의 하드웨어 스레드가 존재함

운영체제의 관점에서 볼 때는 **총 8개의 논리적 CPU가 존재**

`Intel` 프로세서는 **“하이퍼 스레딩(동시 다중 스레딩 또는 SMT)”** 라는 용어를 사용

    👉🏻 **단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것을 설명**하기 위함

<br>
<br>

일반적으로 처리기를 다중 스레드화 하는 데에는 2가지 방법이 존재함

**1️⃣ 거친 다중 스레딩**

- 스레드가 메모리 스톨과 같은 **긴 지연시간을 가진 이벤트가 발생할 때까지 한 코어에서 수행됨**

  👉🏻 긴 지연시간을 가진 이벤트 : 메모리 스톨 등

- 긴 지연시간을 가진 이벤트에 의한 지연에 의해 코어는 다른 스레드를 실행하게 됨
- 프로세서 코어에서 다른 스레드가 수행되기 전에 명령어 파이프라인이 완전히 정리되어야 함

  👉🏻 **스레드 간 교환에는 비용이 많이 들음**

- 새로운 스레드가 실행을 시작하면 자신의 명령어들로 파이프라인을 채움

<br>
<br>

**2️⃣ 세밀한 다중 스레딩**

- 명령어 주기의 경계에서 같이 좀 더 세밀한 정밀도를 가진 시점에서 스레드 교환이 발생함
- 세밀한 시스템의 구조적 설계는 **스레드 교환을 위한 회로를 포함**

  **👉🏻 스레드 간 교환 비용이 적음**

<br>
<br>

다중 스레드 다중 코어 프로세서는 그림과 같이 현실적으로 두 개의 다른 스케줄링 단계가 필요함

<img width="441" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/2c0510b6-04d2-40dd-9812-7d814a8e90c9">

물리적 코어의 자원은 하드웨어 스레드 간에 공유되어야 함

👉🏻 처리 코어는 한 번에 하나의 하드웨어 스레드만 실행할 수 있음

👉🏻 결과적으로 다중 스레드 다중 코어 프로세서는 두 개의 다른 스케줄링 단계가 필요함

<br>

**1단계 : 운영체제가 각 하드웨어 스레드에서 실행할 소프트웨어 스레드를 선택하는 스케줄링 결정**

👉🏻 이 스케줄링 수준 대해서 운영체제는 알고리즘을 포함해 임의의 스케줄링 알고리즘을 선택할 수 있음

<br>

**2단계 : 각 코어가 실행할 하드웨어 스레드를 결정하는 방법을 명시함**

이 상황에서 채택할 수 있는 몇 가지 전략이 존재함

<br>

**1️⃣ RR을 사용해 처리 코어에 하드웨어 스레드를 스케줄 ✅**

- 가장 간단한 방법
- `UltraSPARC` `T3` 에 의해 채택된 접근 방법

<br>

2️⃣ **각 하드웨어 스레드에는 0~7까지의 동적 긴급도 배정(0: 가장 낮음 / 7: 가장 높음)**

- 코어당 2개의 하드웨어 관리 스레드를 가진 이중 코어 프로세서인 `Intel Itanium` 에서 사용
- 스레드 교환을 촉발할 수 있는 5가지 이벤트를 식별
    - 이벤트 발생 시 : 스레드 - 교환 회로가 두 스레드의 긴급도를 비교해 높은 긴급도를 가진 스레드를 채택해 처리 코어에서 실행

<br>
<br>

**❗️1단계와 2단계가 상호배타적이지 않아도 됨(동시에 발생 OK)**

운영체제 스케줄러가 프로세서 자원 공유를 인식하면 보다 효과적인 스케줄링 결정을 내릴 수 있음

<br>

CPU에 2개의 처리 코어가 있고, 코어에 2개의 하드웨어 스레드가 있다고 가정하자

이 시스템에서 두 개의 소프트웨어 스레드가 실행 중이면, 동일한 코어 또는 서로 다른 코어에서 실행될 수 있음

👉🏻 둘 다 동일한 코어에서 실행되도록 스케줄 된 경우엔 프로세서 자원을 공유해야 하기 때문에, 서로 다른 코어에서 스케줄 될때보다 느리게 진행될 수 있음

<br>

운영체제가 프로세서 자원 공유 수준을 알고 있다면 자원을 공유하지 않는 논리 프로세서에 소프트웨어 스레드를 스케줄 할 수 있음

<br>
<br>

### 3. 부하 균등화

📢 ***부하 균등화(Load Balancing) : SMP 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도하는 것 <br>
✔️ 각 처리기가 실행할 스레드를 위한 자신만의 준비 큐를 갖고 있는 시스템에서만 필요한 기능 <br>
✔️ 공통의 실행 큐만 있는 시스템에서 한 처리기가 쉬게 되면, 바로 공통 큐에서 새로운 프로세스를 선택하기 때문에 부하 균등화는 필요하지 않음***

<br>

SMP 시스템에서 처리기가 여러 개인 것을 최대한 활용하기 위해선 **부하를 균등하게 배분하는 것이 매우 중요**

부하 균등화를 위해서는 2가지 일반적 접근법 존재

**1️⃣ push 이주 방식**

- 특정 태스크가 주기적으로 각 처리기의 부하를 검사
- 불균형 상태로 밝혀진다면 과부하인 처리기에서 쉬고 있거나 한가한 처리기로 스레드를 이동

  👉🏻 부하를 분배

<br>
<br>

**2️⃣ pull 이주 방식**

- 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull
- push / pull은 서로 상호 배타적일 필요는 없음 👉🏻 실제로 부하 균등화 시스템에서 병렬적으로 구현

  ex) Linux CFS 스케줄러, FreeBSD 시스템에서 가용한 ULE 스케줄러는 두 방식을 모두 구현함

<br>
<br>

균등 부하의 개념은 다른 의미를 가질 수 있음

1) 모든 큐에 대략 같은 수의 스레드가 있어야 함

2) 균등이랑 모든 큐에 스레드 우선순위를 균등하게 분배해야 함

3) 특정 상황에서는 이런 전략 중 어떤 것도 충분하지 않을 수 있음

👉🏻 이런 전략들은 스케줄링 알고리즘의 목표와 상충할 수 있음

<br>
<br>

### 4. 처리기 선호도

스레드가 특정 처리기에서 실행 중일 때 캐시 메모리에 어떤 일이 벌어지는가 고려해 보자

👉🏻 스레드에 의해 가장 최근에 접근된 데이터가 그 처리기의 캐시를 채우게 됨

👉🏻 스레드에 의한 잇따른 메모리 접근은 캐시 메모리에서 만족함(warm cache)

<br>
<br>

**🤔 스레드가 다른 처리기로 이주한다면 ?**

첫 번째 프로세서의 캐시 메모리 내용은 무효화 및 두 번째 프로세서의 캐시는 다시 채워져야 함

👉🏻 캐시 무효화 및 다시 채우는 비용은 많이 들음

👉🏻 이주 대신 같은 프로세서에 계속 실행시키면서 warm cache를 이용하려고 함 : ***“프로세서 선호도”***

- 다른 프로세서로 이동시키지 않고 같은 프로세서에 실행시키는 것이 훨씬 이득
- SMP를 지원하는 대부분 운영체제에서 사용하는 방법
- 프로세스는 현재 실행 중인 프로세서에 대한 선호도를 보임

<br>
<br>

스케줄링 가능한 스레드의 큐를 구성하기 위해 **앞서 설명한 두 가지 전략은 프로세서 선호도에 영향을 미침**

1️⃣ **공통 준비 큐 접근 방식**

- 선택된 스레드는 어느 처리기에선 실행될 수 있음
- 스레드가 새 프로세서에 스케줄 되면 해당 프로세서의 캐시를 다시 채워야 함

<br>
<br>

**2️⃣ 프로세서마다 자신만의 큐를 사용**

- 스레드는 항상 동일한 프로세서에 스케줄 되므로 warm cache의 내용을 활용 가능
- 기본적으로 프로세서 별 준비 큐는 프로세서 선호도를 무료로 제공

<br>
<br>

처리기 선호도는 여러 형태를 띔

**1️⃣ 약한 선호도(soft affinity)**

- 운영체제가 같은 처리기에서 프로세스를 실행시키기 위해 노력하지만, 보장하지는 않음
- 운영체제는 프로세스를 특정 처리기에서 실행시키려고 하지만 처리기 사이를 이주하는 것은 가능

<br>
<br>

**2️⃣ 강한 선호도(hard affinity)**

- 프로세스는 자신이 실행될 처리기 집합을 명시할 수 있는 시스템 콜
- `Linux` 같은 몇몇 시스템이 사용됨

<br>

많은 시스템은 약한 선호도와 강한 선호도를 모두 지원함

예를 들어, `Linux` 는 약한 선호도를 구현하고 있지만 강한 선호도를 지원하는 `sched_setafficnity()` 시스템 콜도 제공하고 있음

- `ched_setafficnity()` : 스레드가 실행할 수 있는 CPU 집합을 지정할 수 있게 함

<br>
<br>

시스템의 메인 메모리 아키텍처는 프로세서 선호도 문제에도 영향을 줄 수 있음

각각 고유한 CPU와 로컬 메모리를 가진 두 개의 물리적 프로세서 칩이 있는 NUMA(Non Uniform Memory Access)를 특징으로 하는 아키텍처를 보여줌

시스템 연결망을 통해 NUMA 시스템의 모든 CPU가 하나의 물리적 주소 공간을 공유할 수 있지만 CPU는 다른 CPU의 로컬 메모리보다 자신의 로컬 메모리에 더 빠르게 액세스 할 수 있음

운영체제의 CPU 스케줄러 및 메모리 배치 알고리즘이 NUMA를 인식하고 협력하는 경우 특정 CPU에 스케줄 된 스레드를 CPU가 있는 위치에 가장 가까운 메모리에 할당해 가능한 가장 빠른 메모리 액세스를 제공할 수 있음

<img width="738" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/308c47b5-60e4-4f29-806f-d48b4c6ef39f">

<br>
<br>

> ***부하 균등화와 메모리 액세스 시간 최소화 사이에는 갈등이 생김**
프로세서 간에 스레드를 이주하면 NUMA 시스템에서 손해가 발생할 수 있는데 이 경우 스레드는 더 긴 메모리 액세스 시간이 필요한 프로세서로 이동될 수 있음
⭐️ 현대 다중 코어 NUMA 시스템에 대한 스케줄링 알고리즘은 상당히 복잡해짐*
>

<br>
<br>

### 5. 이기종 다중 처리

지금까지 설명한 예에서 모든 프로세서는 기능 면에서 동일하므로 어느 스레드건 모든 처리 코어에서 실행될 수 있음

유일한 차이점은 메모리 액세스 시간이 NUMA 시스템뿐만 아니라 부하 균등화 및 프로세서 선호도 정책에 따라 달라질 수 있다는 것

<br>

모바일 시스템은 현재 다중 코어 아키텍처가 채택되어 있지만 일부 시스템은 **이기종 다중 처리(Heterogeneous Multiprocessing; HMP)** 로 설계

👉🏻 동일한 명령어 집합을 수행

전력 소비를 유휴 수준으로 조정하는 기능을 포함해 클록 속도 및 전력 관리 측면에서 차이가 나는 코어를 사용하여 설계된 것

<br>

시스템 및 사용자 태스크는 모든 코어에서 실행될 수 있음 👉🏻 **비대칭 다중 처리 형태는 아님**

HMP의 목적은 작업의 특정 요구에 따라 특정 코어에 작업을 할당하여 전력 소비를 더 잘 관리하는 것

<br>
<br>

이를 지원하는 ARM 프로세서의 경우 이 유형의 아키텍처를 **big.LITTLE**이라고 부름

**고성능 big 코어 + 에너지 효율적인 LITTLE 코어**

👉🏻 big 코어 : 많은 에너지를 소비하므로, 짧은 시간 동안만 사용해야 함

👉🏻 little 코어 : 더 적은 에너지를 사용하므로 더 오랫동안 사용할 수 이씀

<br>

`장점`

- 긴 시간 동안 실행해야 할 작업을 little 코어에 할당해 배터리 충전을 보존하는데 도움을 줌
    - 백그라운드 작업과 같은 것들이 긴 시간 동안 실행해야 할 작업
- 대화형 응용 프로그램을 big 코어에 할당
    - 대화형 응용 프로그램 : 많은 처리 능력이 필요하지만, 짧은 기간 동안 실행
- 모바일 장치가 절전 모드인 경우
    - big 코어를 비활성화하고, little 코어에만 의존

<br>

`Windows 10` 은 스케줄링 정책을 선택할 수 있게 하여 HMP 스케줄링을 지원함

<br>
<br>

## 💭 실시간 CPU 스케줄링

실시간 CPU 스케줄링은 **연성 실시간 시스템**과 **경성 실시간 시스템**으로 구분

<br>

1️⃣ **연성 실시간 시스템**

- 중요한 실시간 프로세스가 스케줄 되는 시점에 관해 아무런 보장을 하지 않음
- 오직 중요 프로세스가 그렇지 않은 프로세스들에 비해 우선권을 가진다는 것만 보장

<br>

2️⃣ **경성 실시간 시스템**

- 태스크는 반드시 마감시간까지 서비스를 받아야 함 👉🏻 더 엄격한 요구 조건을 만족해야 함
- 마감시간이 지난 이후에 서비스를 받는 것은 서비스를 받지 않는 것과 같음

<br>
<br>

### 1. 지연시간 최소화

실시간 시스템의 이벤트 중심의 특성을 생각해보자

시스템은 일반적으로 실시간으로 발생하는 이벤트를 기다림

이벤트가 발생하면, 시스템은 가능한 한 빨리 그에 응답하고 그에 맞는 동작을 수행해야 함

- 이벤트의 소프트웨어적 발생 : 타이머 만료 등
- 이벤트의 하드웨어적 발생 : 원격으로 제어되던 장치가 방해물을 만났을 때

<br>

**이벤트 지연시간 :** 이벤트가 발생해서 그에 맞는 서비스가 수행될 때까지의 시간

<img width="458" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/61a88090-4c07-4d8d-bdef-a44e38a8f1c2">

<br>

일반적으로 이벤트가 다르면 그에 따른 지연시간 역시 다름

다음 2가지 유형의 지연시간이 실시간 시스템의 성능을 좌우하게 됨

<br>

**1️⃣ 인터럽트 지연시간**
<img width="480" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3597b819-d08a-4330-aa98-07d973f497e6">

<br>

- **CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기까지의 시간**을 말함
- 인터럽트가 발생하면 다음과 같은 과정

  1) 수행 중인 명령어 완수

  2) 발생한 인터럽트의 종류 결정

  3) 결정한 인터럽트 서비스 루틴(ISR)을 사용해 인터럽츠를 처리하기 전 현재 수행 중인 프로세스의 상태를 저장

<br>

- 실시간 태스크의 즉시 수행을 위해 **인터럽트 지연시간을 최소화하는 것은 실시간 운영체제의 핵심**
  - 경성 실시간 시스템에서는 인터럽트 지연시간을 최소화 + 정해진 시간보다 작아야 함

    👉🏻 엄격한 요구조건을 만족시키기 위해

<br>

- 인터럽트 지연시간에 영향을 주는 요인 중 하나는 커널 데이터 구조체를 갱신하는 동안 인터럽트가 불능케되는 시간

  👉🏻 실시간 운영체제는 인터럽트 불능 시간을 매우 짧게 해야 함

<br>
<br>

**2️⃣ 디스패치 지연시간**

<img width="564" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5093e1ea-a5c0-455e-af35-dbb4d4a531ae">

- **스케줄링 디스패처가 하나의 프로세스를 블록 시키고 다른 프로세스를 시작하는 데까지 걸리는 시간**을 말함
- CPU를 즉시 사용해야 하는 실시간 태스크가 있다면, 이 지연시간을 최소화해야 함

  👉🏻 디스패치 지연시간을 최소화하는 가장 효과적인 방법 : **선점형 커널**

<br>

- 디스패치 지연시간의 충돌 단계는 2가지 요소로 구성되어 있음

  1) 커널에서 동작하는 프로세스에 대한 선점

  2) 높은 우선순위의 프로세스가 필요한 자원을 낮은 우선순위 프로세스 자원이 방출

<br>

- 충돌 단계에 이어 디스패치 단계는 우선순위가 높은 프로세스를 사용 가능한 CPU에 스케줄 함

<br>
<br>

### 2. 우선순위 기반 스케줄링

실시간 운영체제에서 가장 중요한 기능

👉🏻 실시간 프로세스에 CPU가 필요할 때 바로 응답해주는 것

👉🏻 실시간 운영체제의 스케줄러는 선점을 이용한 **우선순위 기반의 알고리즘**을 지원해야 함

<br>
<br>

➕ **선점 및 우선순위 기반의 스케줄링 알고리즘**

- 각각의 프로세스의 중요성에 따라 우선순위를 부여함
- 더 중요한 태스크가 그렇지 않은 태스크들보다 더 높은 우선순위를 갖게 됨
- 스케줄러가 선점 기법을 제공한다면, 현재 CPU를 이용하고 있는 프로세스가 더 높은 우선순위를 갖는 프로세스에 선점될 수도 있음

<br>

`Linux`, `Windows`, `Solaris` 운영체제에서 연성 실시간 스케줄링의 사례를 확인할 수 있음

실시간 프로세스에게 가장 높은 스케줄링 우선권을 부여함

`Windows` 에는 32개의 우선순위가 존재함

- 가장 높은 순위인 16~31의 값이 실시간 프로세스들에 해당

<br>
<br>

➕ **경성 실시간 시스템에 적합한 스케줄링 알고리즘**

- 선점 및 우선순위 기반의 스케줄러를 통해 제공할 수 있는 것은 연성 실시간 기능뿐
- 경성 실시간 시스템에서의 마감시간 내에 확실히 수행되는 것을 보장하지 못함
- 경성 실시간 시스템에 맞는 부가적인 스케줄링 기법이 필요함

<br>

`개별 스케줄러에 스케줄 될 프로세스의 특성`

- 프로세스들은 주기적임 👉🏻 프로세스들은 일정한 간격으로 CPU가 필요함
- 각각의 주기 프로세스들은 CPU 사용권을 얻을 때 마다 `t`, `d`, `p` 가 정해져 있음
  - `t` : 고정된 수행시간
  - `d` : CPU로부터 반드시 받아야 하는 마감시간
  - `p` : 주기
  - `0 ≤ t ≤ d ≤ p`
  - 주기 태스크의 실행 빈도는 `1/p`

<br>

- 스케줄러는 이들의 주기, 마감시간, 수행 시간 사이의 관계를 이용해 마감시간을 정함
- 스케줄러는 주기적 프로세스의 실행 빈도에 따라서 우선순위를 정함

<img width="545" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/cae6ac3e-00e8-40b2-9e73-26e952034199">

<br>
<br>

이런 형식의 스케줄링에서 일반적이지 않은 것은 프로세스가 자신의 마감시간을 스케줄러에게 알려줘야 할 수도 있음 👉🏻 **승인 제어** 알고리즘을 사용

<br>

승인 제어를 통해 스케줄러는 마감시간 이내에 완수할 수 있는 프로세스는 실행을 허락하고, 그렇지 못한 경우에는 요구를 거절함

<br>
<br>

### 3. Rate-Monotonic 스케줄링
📢 ***Rate-Monotonic 스케줄링 : 선점 가능한 정적 우선순위 정책을 이용해 주기 태스크들을 스케줄 <br>
✔️ 각각의 주기 태스크들은 시스템 진입 시에 주기에 따라서 우선순위가 정해짐 (짧을수록 높은 순위)***

<br>

낮은 우선순위의 프로세스가 실행 중이고 높은 우선순위의 프로세스가 실행 준비가 되면, 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점함

해당 정책은 CPU를 더 자주 필요로 하는 태스크에 더 높은 우선순위를 주려는 원리에 기반을 두고 있음

<br>

RM 스케줄링은 주기 프로세스들의 처리 시간은 각각의 CPU 버스트와 같다고 가정

👉🏻 프로세스가 CPU를 차지한 시간은 각각의 CPU 버스트 시간과 같음

<br>
<br>

**🤔 P2가 P1보다 높은 우선순위를 갖고 있을때의 스케줄링 ?**

2개의 프로세스 P1, P2가 있다고 가정해보자

- P1 주기 = 50, 수행 시간 = 20
- P2 주기 = 100, 수행 시간 = 35

두 프로세스가 마감시간을 충족시키도록 스케줄링이 가능할까 ?

     ✅ CPU 이용률, 즉 **주기에 대한 수행 시간을 계산**해보면 해결 가능함

<br>

- P1 CPU 이용률 ⇒ 20/50 = 0.40
- P2 CPU 이용률 ⇒ 35/100 = 0.35

총 CPU 이용률 ⇒ 75%이므로, 마감시간을 모두 충족시킴

<br>

◎ **RM 스케줄링을 사용하지 않은 경우**

<img width="582" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/b7515917-7929-41a0-9c1a-b8693ddb53f7">

👉🏻 P1의 마감시간이 50인데 55에 끝났기 때문에 스케줄러 P1의 마감시간을 충족시키지 못함

<br>

◎ **RM 스케줄링을 사용한 경우**

<img width="578" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/4c013bd0-cc54-4611-bee8-a26613dfbce1">

👉🏻 P1의 주기가 P2의 주기보다 짧음

👉🏻 즉, P1의 우선순위가 P2보다 높음

<br>

`과정`

```bash
1. P1이 먼저 수행이 시작해 시간 20에 수행 종료 ⇒ P1 마감시간 만족

2. 바로 P2가 수행을 시작 후 시간 50까지 수행을 끝냄 ⇒ P1에게 선점
    - 5ms 의 할당 시간이 남아있음

3. P1은 시간 70까지 수행을 하고, 스케줄러는 다시 P2를 수행시킴

4. P2는 남은 5ms의 시간의 수행을 75에 끝냄 ⇒ P2 마감시간 만족

5. 시스템은 시간 100까지 유휴시간을 갖고, P1이 다시 스케줄
```

<br>
<br>

RM 스케줄링 기법이 스케줄 할 수 없는 프로세스 집합의 경우 정적 우선순위를 이용해 다른 알고리즘들 역시 스케줄 할 수 없는 측면에서 최적이라고 할 수 있음

**But,** 많은 제약이 있음

CPU 이용률 한계가 있기 때문에 **CPU 자원을 최대화해서 사용하는 것을 불가능**함

N개의 프로세스를 스케줄 하는 데 있어 허용하는 CPU 이용률

<img width="452" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/da3f50d5-64e2-4a7c-a964-6edc6af7cd05">

<br>
<br>

### 4. **Earliest-Deadline-First 스케줄링(EDF)**
📢 ***EDF : 마감시간에 따라 우선순위를 동적으로 부여 <br>
✔️ 마감시간이 빠를수록 우선순위가 높아짐***

<br>

해당 정책에서는 프로세스가 실행 가능하게 되면, 자신의 마감시간을 시스템에게 알려야 함

우선순위는 **새로 실행 가능하게 된 프로세스의 마감시간에 맞춰 다시 조정**

👉🏻 우선순위가 고정되어 있는 RM 스케줄링과는 다름

<br>
<br>

**🤔 EDF 스케줄링 예시**

2개의 프로세스 P1, P2가 있다고 가정해보자

- P1 주기 = 50, 수행 시간 = 25
- P2 주기 = 80, 수행 시간 = 35

<img width="741" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/0361918f-68a3-487c-84e9-6248aacac8a2">

`과정`

```bash
1. P2는 P1의 CPU 버스트가 끝난 후 수행을 시작
		- 처음에는 프로세스 P1의 마감시간이 더 빠르기 때문에 P1의 우선순위가 P2보다 높음

2. 시간 50에서 P2의 마감시간은 80, P1의 마감시간은 100
		- EDF에 의해 P2의 우선순위가 더 높아 P2를 계속 수행
		- rate-monotonic 스케줄링에서는 시간 50에서 P1이 선점

3. 시간 60에 P2의 CPU 버스트가 끝난다.
		- P1과 P2 모두 첫 번째 마감시간을 만족

4. 프로세스 P1은 시간 60에 다시 수행을 시작하여 시간 85에 두 번째 CPU 버스트가 끝남

5. P2는 다시 수행을 시작하고 다음 주기인 시간 100에 P1에게 선점
		- P1의 마감시간 = 150, P2의 마감시간 = 165로 P1의 우선순위가 더 높음

6. 시간 125에서 P1은 CPU 할당량을 완수하고 P2가 수행을 시작하여 시간 145에 끝남
		- 둘 다 마감시간을 만족

7. 시간 150까지 유휴시간을 가지고 다시 P1이 스케줄 되어 수행을 시작
```

<br>
<br>

> *EDF 스케줄링 알고리즘은 프로세스들이 주기적일 필요도 없고, 할당 시간도 상수 값으로 정해질 필요도 없지만 **프로세스가 실행 가능해질때 자신의 마감시간을 스케줄러에게 알려주는 것이 가장 핵심**인 알고리즘
이론적으로는 최적이지만 **프로세스 사이, 인터럽트 핸들링 때의 문맥교환 비용에 의해 100% CPU 이용은 불가***
>

<br>
<br>

### 5. 일정 비율의 몫 스케줄링
📢 ***일정 비율의 몫 스케줄링 : 모든 응용들에게 T개의 시간 몫을 할당해 동작
✔️ 한 개의 응용이 N개의 시간 몫을 할당받으면 그 응용은 모든 프로세스 시간 중 N/T를 할당받는 것***

<br>
<br>

일정 비율의 몫 스케줄러는 **승인 제어 정책과 함께 동작**해야 함

- 사용 가능한 충분한 몫이 있을 경우에만 몫을 요구하는 클라이언트들에게만 실행을 허락

<br>
<br>

### 6. POSIX 실시간 스케줄링

`POSIX` 는 실시간 컴퓨팅용으로 `POSIX.1b` 라는 확장 제공

실시간 스레드를 위해 두 개의 스케줄링 클래스 정의

- `SCHED FIFO`
  - FIFO 큐를 사용해 먼저 온 것을 먼저 서비스하는 정책에 따라 스레드를 스케줄
  - FIFO 큐의 앞에 있는 가장 높은 우선순위의 실시간 스레드는 종료되거나 블록 될 때까지 CPU를 할당받음
- `SCHED RR`
  - RR 정책을 사용하며, 같은 우선순위의 스레드에 시간 할당량을 제공하는 것을 제외하면 FIFO와 비슷함

<br>

`POSIX` API는 스케줄링 정책에 관한 정보를 지정하고 얻어내는 다음과 같은 두 개의 함수를 제공

- `pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy)`
- `pthread_attr_setschedpolicy(pthread_attr_t *attr, int *policy)`

<br>

두 함수의 첫 번째 인자는 스레드의 속성 집합에 대한 포인터

두 번째 인자는 현재의 스케줄링 정책이거나, `SCHED_FIFO` , `SCHED_RR` , `SCHED_OTHER` 와 같은 정책을 표현하는 정수 값

두 함수 모두 에러가 발생하면 `0` 이 아닌 값을 반환

<img width="508" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/d2ebd83c-4448-49e7-a840-b5dbbe190112">

<br>
<br>

## 💭 알고리즘의 평가

**🤔 특정 시스템을 위한 CPU 스케줄링 알고리즘은 어떻게 선택하는가 ?**

👉🏻 **알고리즘을 선택하는 것은 매우 까다로운 일**

<br>

첫 번째 문제는 알고리즘을 선택하는데, 사용할 기준을 정의하는 것임

기준은 종종 CPU 이용률, 응답 시간 또는 처리량에 의해 정의됨

알고리즘을 선택하기 위해, 먼저 이들 값의 상대적인 중요성을 반드시 정의해야 함

<br>

기준은 다음과 같은 다수의 대책을 포함할 수 있음

- 최대 응답 시간이 300밀리초라는 제약 조건에서 CPU 이용률을 극대화함
- 총 처리 시간이 전체 실행 시간에 평균적으로 선형 비례가 되도록 처리량을 극대화함

<br>

선택 기준의 정의되면, 여러 가지 알고리즘들을 평가하기를 원함

<br>
<br>

### 1. 결정론적 모델링

**◎** **분석적 평가(analytic evaluation)**

- 평가 방법의 중요한 부류 중 하나
- 주어진 작업 부하에 대한 알고리즘의 성능을 평가하는 공식이나 값을 생성하기 위해 주어진 알고리즘과 시스템 작업 부하를 이용함

<br>

**◎ 결정론적 모델링(deterministic modeling)**

- 사전에 정의된 특정 작업 부하를 받아들여 그 작업 부하에 대한 각 알고리즘의 성능을 정의
- 단순하고 빠름

<br>
<br>

예를 들어, 아래와 같은 작업 부하가 있다고 가정하자

<img width="503" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/b9e940aa-022b-4ba2-b5dc-ac74d3bf7ac3">

**🤔 해당 프로세스 집합에 대해 FCFS, SJF, RR(시간 할당량  = 10ms) 스케줄링 알고리즘을 고려했을 때, 어떤 알고리즘의 평균 대기 시간이 가장 짧은가 ?**

- `FCFS`

<img width="488" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/a6b1892c-20ed-4d23-a786-a65b3bab5378">

  👉🏻 대기 시간 : 28ms

<br>

- `비선점 SJF`

<img width="487" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/648e2bed-321b-4949-8b4e-5feeebda721c">

  👉🏻 대기 시간 : 13ms

<br>

- `RR`

<img width="484" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3ac4c17e-4e7a-41f2-8852-78dc4723dc67">
  👉🏻 대기 시간 : 23ms

<br>

`결론`

*✅ SJF 정책의 평균 대기 시간이 FCFS 스케줄링 보다 절반정도 작음*

*✅ RR 알고리즘은 중간 정도*

<br>
<br>

> *결정론적 모델링은 **단순하고 빠르며**, 이것은 **알고리즘들을 비교할 수 있도록 정확한 값을 제공**함*
>
>
> ***But,** 입력으로 정확한 숫자를 요구하고 응답도 비교한 것들의 경우에만 적용됨*
>
>  *결정론적 모델링은 스케줄링 알고리즘을 설명하고, 예를 제공하는 데 사용*
>
> ***동일한 프로그램을 반복 실행하고, 프로그램의 처리 요구 사항을 정확하게 측정할 수 있는 경우 사용**함*
>

<br>
<br>

### 2. 큐잉 모델

많은 시스템에서 실행되는 **프로세스들은 날마다 변화하기 때문에, 결정론적 모델링을 사용할 수 있는 프로세스들의 정적인 집합이 없음**

**But,** 결정할 수 있는 것은 **CPU**와 **I/O 버스트의 분포**

<br>

이들의 분포는 측정 가능하고, 근삿값을 계산하거나 추정할 수 있음

특정 CPU 버스트의 확률을 기술하는 수학적 공식을 얻을 수 있음

보통 지수적이며, 평균으로 기술됨

이 분포로부터 알고리즘 대부분에 대한 **평균 처리량, 이용률, 대기 시간 등을 계산**하는 것이 가능함

<br>
<br>

컴퓨터 시스템은 서버들의 네트워크로 기술되는데, 각 서버는 대기 프로세스들의 큐를 갖고 있음

- CPU → 준비 큐를 가진 서버
- I/O 시스템 → 장치 큐를 가진 서버

<br>

도착률과 서비스율을 알기 때문에, 우리는 **이용률, 평균 큐 길이, 평균 대기 시간 등을 계산**할 수 있고, 이런 영역에 관한 연구를 **“큐잉 네트워크 분석(queueing network analysis)”** 라고 함

<br>
<br>

➕  **Little’s formula 공식**

: 어떤 스케줄링 알고리즘이나, 어떤 도착 분포에서도 성립하기 때문에 특히 유용함

<img width="645" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/3c3f14c9-8e06-48da-9c7a-37d7e862ecfa">

<br>

프로세스가 대기하는 시간 `W` 동안 `𝜆 * W`개의 새로운 프로세스들이 큐에 도착할 것임

만일 시스템이 안정된 상태라면, 큐를 떠나는 프로세스와 도착하는 프로세스의 수가 같아야 함

3개의 변수 중 2개의 변수를 알고 있다면 나머지 하나를 계산할 수 있음

<br>
<br>

> *분석할 수 있는 알고리즘과 분포의 부류가 상당히 제한되어 있는데, 복잡한 알고리즘이나 분포와 관련된 수학적 분석이 어려움
정확하지 않을 수 있는 다수의 독립된 가정을 하는 것이 일반적으로 필요함*
>
>
> *⭐️* ***큐잉 모델들은 종종 단지 실제 시스템의 근사치이며 연산된 결과의 정확성에는 의심의 여지가 있음***
>

<br>
<br>

### 3. 모의실험

모의실험을 하는 것은 컴퓨터 시스템의 모델을 프로그래밍하는 것을 포함함

모의실험을 실행하면서 알고리즘의 성능을 나타내는 통계들을 수집하고 인쇄함

<br>

모의실험을 구동하기 위한 자료들은 여러 가지 방법으로 생성할 수 있음

**◎ 난수 발생기(random number generator)**

- 가장 보편적인 방법
- 확률 분포에 따라 프로세스 , CPU 버스트 시간, 도착, 출발 등을 생성하기 위해 프로그램됨
- 분포는 수학적으로 [균등, 지수, 푸아송] 또는 경험적으로 정의될 수 있음
  - 경험적으로 분포를 정의하려면, 연구 대상이 되는 실제 시스템에 대한 측정이 행해짐

<br>

- 만들어진 분포는 모의실험을 구동하는 데 사용
- **But,** 분포에 의해 주도되는 모의실험은 실제 시스템에서 연속적인 이벤트들 사이의 관계 때문에 **부정확할 수 있음**
- 빈도수 분포는 단지 각 이벤트가 얼마나 많이 발생하는가를 의미함

  👉🏻 이들의 생성 순서에 대해선 아무런 정보도 제공하지 못함

<img width="644" alt="image" src="https://github.com/SeoYunnn/TIL/assets/120713987/5fcb1c66-f389-42d5-9223-fcd0c481afee">
모의실험에 의한 CPU 스케줄러의 평가

이를 해결하기 위해선 **“추적 파일”** 을 사용할 수 있음

실제 이벤트들의 **순서를 기록해 추적 파일을 생성**함

👉🏻 이 순서를 모의실험을 행하는 데 사용할 수 있음

<br>

***추적 파일은 실제 입력들과 정확히 동일한 입력으로 2개의 알고리즘을 비교하는 좋은 방법임***

👉🏻 ***해당 방법으로 입력에 대한 정확한 결과 생성 가능***

<br>
<br>

> ***모의실험**은 컴퓨터를 오래 사용하기 때문에 **매우 큰 비용이 소모**될 수 있고 모의실험이 **상세할수록 더 정확한 결과를 얻을 수 있지만 컴퓨터 사용시간이 더 필요**함
**추적 파일**은 **대량의 저장공간을 요구**할 수 있으며 모의실험기의 설계, 코딩, 오류 수정은 매우 중요한 작업이 될 수 있음*
>

<br>
<br>

### 4. 구현

실제 운영 환경에서의 평가를 위해 실제 코드로 작성해 운영체제에 넣고 실행해 보는 방식

해당 방식은 **비용이 많이 들음**

- 알고리즘 코드 작성 비용
- 작성한 코드를 지원하기 위해 운영체제 코드와 그에 따른 자료구조를 변경하는 비용
- 가상 머신에서 변경 사항을 테스트하는 비용(전용 하드웨어가 아닌 이상)

**회귀 테스트**를 통해 변경사항이 더 나빠지지 않았으며, 버그가 발생하지 않았음을 확인할 수 있음

<br>

이 구현 방식의 어려움은 ***“알고리즘이 사용되는 환경의 변화”***

환경은 스케줄러가 보이는 성능의 결과에 따라서 변화할 수도 있음

짧은 프로세서에 우선순위를 주면, 사용자들은 큰 프로세스를 작은 프로세스들의 집합으로 나눌 것임

비대화형 보다 대화형 프로세스에 우선순위를 주면, 사용자들은 컴퓨터를 대화형으로 사용할 것임

<br>

✅ 해당 문제를 해결하기 위해서는 **완전한 조치의 집합을 캡슐화한 도구 또는 스크립트를 사용**하고, 해당 도구를 **반복적으로 사용하며 결과를 측정하는 동안 도구를 사용해 해결**함

<br>
<br>

**◎ 융통성 있는 스케줄링 알고리즘**

- 시스템 관리자 또는 사용자에 의해 알고리즘이 특정 응용이나 응용 집합에 맞도록 조정될 수 있게 함

  ex) 고성능 그래픽 기반 응용을 수행하는 워크스테이션은 웹 서버나 파일 서버와는 다른 스케줄링 요구를 가질 수 있음

  일부 운영체제는 시스템 관리자가 특정 시스템 구성을 위해 스케줄링 변수들을 미세 조정할 수 있게 허용함

- 프로세스나 스레드의 우선순위를 변경하는 API를 사용하는 것

  ex) `Java` , `POSIX` , 및 `WinAPI` 가 이런 함수를 제공

- **But,** 종종 성능조정이 더 일반적인 상황에서는 개선된 성능을 낳지 않을 수도 있음